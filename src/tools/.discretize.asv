"""
An instance filter that discretizes a range of numeric attributes in the dataset into nominal attributes. Discretization is by Fayyad & Irani's MDL method (the default).

For more information, see:

Usama M. Fayyad, Keki B. Irani: Multi-interval discretization of continuous valued attributes for classification learning. In: Thirteenth International Joint Conference on Artificial Intelligence, 1022-1027, 1993.

Igor Kononenko: On Biases in Estimating Multi-Valued Attributes. In: 14th International Joint Conference on Articial Intelligence, 1034-1040, 1995.
BibTeX:

 @inproceedings{Fayyad1993,
    author = {Usama M. Fayyad and Keki B. Irani},
    booktitle = {Thirteenth International Joint Conference on Articial Intelligence},
    pages = {1022-1027},
    publisher = {Morgan Kaufmann Publishers},
    title = {Multi-interval discretization of continuousvalued attributes for classification learning},
    volume = {2},
    year = {1993}
 }

 @inproceedings{Kononenko1995,
    author = {Igor Kononenko},
    booktitle = {14th International Joint Conference on Articial Intelligence},
    pages = {1034-1040},
    title = {On Biases in Estimating Multi-Valued Attributes},
    year = {1995},
    PS = {http://ai.fri.uni-lj.si/papers/kononenko95-ijcai.ps.gz}
 }

"""
from __future__ import division, print_function
from containers import Thing
import pandas as pd
from collections import Counter
import numpy as np
from pdb import set_trace
def ediv(lst, lvl=0,tiny=1,
         dull=0.3,
         num=lambda x:x[0], sym=lambda x:x[1]):
  """
  Divide lst of (numbers,symbols) using entropy.
  """
  #----------------------------------------------
  def divide(this,lvl): # Find best divide of 'this' lst.
    def ke(z): return k(z)*ent(z)
    def k(x): return len(Counter(x).keys())
    def ent(x): return sum([-Counter(x)[n]/len(x)*np.log2(Counter(x)[n]/len(x)) for n in Counter(x).keys()])
    lhs,rhs   = [], [sym(x) for x in this]
    n0,k0,e0,ke0= len(rhs),k(rhs),ent(rhs),k(rhs)*ent(rhs)
    cut, least  = None, e0
    last = num(this[0])
    for j,x  in enumerate(this):
      # rhs - sym(x); #nRhs - num(x)
      lhs.append(rhs.pop()); #nLhs + num(x)
      now = num(x)
      if now != last:
        if len(lhs) > tiny and len(rhs) > tiny:
          maybe= len(lhs)/n0*ent(lhs)+ len(rhs)/n0*ent(rhs)
          if maybe < least :
            gain = e0 - maybe
            delta= np.log2(float((3**k0-2)-(ke0- ke(rhs)-ke(lhs))))
            if gain >= (np.log2(n0-1) + delta)/n0:
              cut,least = j,maybe
      last= now
    return cut,least
  #--------------------------------------------
  def recurse(this, cuts,lvl):
    cut,e = divide(this,lvl)
    if cut:
      recurse(this[:cut], cuts, lvl+1);
      recurse(this[cut:], cuts, lvl+1)
    else:
      lo    = num(this[0])
      hi    = num(this[-1])
      cuts += [Thing(at=lo,
                     e=e,_has=this,
                     range=(lo,hi))]
    return cuts
  #---| main |-----------------------------------
  set_trace()
  return recurse(sorted(lst,key=num),[],0)


def discretize(tbl, klass=-1):
  """
  tbl: A Pandas style dataframe.
  klass: index of the dependent variable. Usually -1 (last column)
  """

  # Ignore columns with'?' in their names.
  columns = [t for t in tbl.columns if not '?' in t]

  therows=[r.tolist() for r in tbl[columns].as_matrix()]

  for i, _ in enumerate(columns[:klass]):
    for cut in  ediv(therows, num=lambda x:x[i], sym=lambda x:x[klass]):
      print(cut.range)
    set_trace()
      # for row in cut._has:
      #   row[i] = cut.range

  return pd.DataFrame(np.array(therows, dtype=object),columns=columns)

if __name__=='__main__':
  pass