@article{alves2016,
	title = "Identification and management of technical debt: A systematic 
	mapping study ",
	journal = "Information and Software Technology ",
	volume = "70",
	number = "",
	pages = "100 - 121",
	year = "2016",
	note = "",
	issn = "0950-5849",
	doi = "http://dx.doi.org/10.1016/j.infsof.2015.10.008",
	url = "http://www.sciencedirect.com/science/article/pii/S0950584915001743",
	author = "Nicolli S.R. Alves and Thiago S. Mendes and Manoel G. de Mendonça 
	and Rodrigo O. Spínola and Forrest Shull and Carolyn Seaman",
	keywords = "Technical debt",
	keywords = "Software maintenance",
	keywords = "Software engineering",
	keywords = "Systematic mapping "
}

@inproceedings{munro2005product,
  title={Product metrics for automatic identification of ``bad smell'' design problems in java source-code},
  author={Munro, Matthew James},
  booktitle={11th IEEE International Software Metrics Symposium (METRICS'05)},
  pages={15--15},
  year={2005},
  organization={IEEE}
}

@article{Hall2014,
abstract = {We investigate the relationship between faults and five of Fowler et al.'s least-studied smells in code: Data Clumps, Switch Statements, Speculative Generality, Message Chains, and Middle Man. We developed a tool to detect these five smells in three open-source systems: Eclipse, ArgoUML, and Apache Commons. We collected fault data from the change and fault repositories of each system. We built Negative Binomial regression models to analyse the relationships between smells and faults and report the McFadden effect size of those relationships. Our results suggest that Switch Statements had no effect on faults in any of the three systems; Message Chains increased faults in two systems; Message Chains which occurred in larger files reduced faults; Data Clumps reduced faults in Apache and Eclipse but increased faults in ArgoUML; Middle Man reduced faults only in ArgoUML, and Speculative Generality reduced faults only in Eclipse. File size alone affects faults in some systems but not in all systems. Where smells did significantly affect faults, the size of that effect was small (always under 10 percent). Our findings suggest that some smells do indicate fault-prone code in some circumstances but that the effect that these smells have on faults is small. Our findings also show that smells have different effects on different systems. We conclude that arbitrary refactoring is unlikely to significantly reduce fault-proneness and in some cases may increase fault-proneness.},
author = {Hall, Tracy and Zhang, Min and Bowes, David and Sun, Yi},
doi = {10.1145/2629648},
file = {:home/rkrsn/Documents/Mendeley Desktop/Hall et al. - 2014 - Some Code Smells Have a Significant but Small Effect on Faults.pdf:pdf},
issn = {1049331X},
journal = {ACM Transactions on Software Engineering and Methodology},
keywords = {Software code smells,defects},
mendeley-groups = {ANTI PATTERNS},
number = {4},
pages = {1--39},
title = {{Some Code Smells Have a Significant but Small Effect on Faults}},
url = {http://dl.acm.org/citation.cfm?id=2668018.2629648},
volume = {23},
year = {2014}
}

@Article{madeyski15,
author="Madeyski, Lech
and Jureczko, Marian",
title="Which process metrics can significantly improve defect prediction models? An empirical study",
journal="Software Quality Journal",
year="2015",
volume="23",
number="3",
pages="393--422",
issn="1573-1367",
doi="10.1007/s11219-014-9241-7",
url="http://dx.doi.org/10.1007/s11219-014-9241-7"
}

@article{li07,
  title={An empirical study of the bad smells and class error probability in the post-release object-oriented system evolution},
  author={Li, Wei and Shatnawi, Raed},
  journal={Journal of systems and software},
  volume={80},
  number={7},
  pages={1120--1128},
  year={2007},
  publisher={Elsevier}
}

@article{li15td,
	title={A systematic mapping study on technical debt and its management},
	author={Li, Zengyang and Avgeriou, Paris and Liang, Peng},
	journal={Journal of Systems and Software},
	volume={101},
	pages={193--220},
	year={2015},
	publisher={Elsevier}
}

@inproceedings{ernst15,
	title={Measure it? Manage it? Ignore it? Software practitioners and 
	technical debt},
	author={Ernst, Neil A and Bellomo, Stephany and Ozkaya, Ipek and Nord, 
	Robert L and Gorton, Ian},
	booktitle={Proceedings of the 2015 10th Joint Meeting on Foundations of 
	Software Engineering},
	pages={50--60},
	year={2015},
	organization={ACM}
}

@article{ouni1,
	title={Maintainability defects detection and correction: a multi-objective 
	approach},
	author={Ouni, Ali and Kessentini, Marouane and Sahraoui, Houari and 
	Boukadoum, Mounir},
	journal={Automated Software Engineering},
	volume={20},
	number={1},
	pages={47--79},
	year={2013},
	publisher={Springer}
}

@article{ouni2,
	title={Prioritizing code-smells correction tasks using chemical reaction 
	optimization},
	author={Ouni, Ali and Kessentini, Marouane and Bechikh, Slim and Sahraoui, 
	Houari},
	journal={Software Quality Journal},
	volume={23},
	number={2},
	pages={323--361},
	year={2015},
	publisher={Springer}
}

@inproceedings{ouni3,
	title={Search-based refactoring: Towards semantics preservation},
	author={Ouni, Ali and Kessentini, Marouane and Sahraoui, Houari and Hamdi, 
	Mohamed Salah},
	booktitle={Software Maintenance (ICSM), 2012 28th IEEE International 
	Conference on},
	pages={347--356},
	year={2012},
	organization={IEEE}
}

@INPROCEEDINGS{font1, 
author={F. A. Fontana and V. Ferme and M. Zanoni and R. Roveda}, 
booktitle={2015 IEEE 7th International Workshop on Managing Technical Debt (MTD)}, 
title={Towards a prioritization of code debt: A code smell Intensity Index}, 
year={2015}, 
pages={16-24}, 
keywords={inspection;software maintenance;source code (software);Qualitas Corpus;code debt prioritization;code decay;code smell detection;code smell intensity index;code smells inspection;false positive code smell instance;intensity distribution;maintenance problems;refactoring;technical debt;Feature extraction;Indexes;Informatics;Java;Maintenance engineering;Measurement;Prototypes}, 
doi={10.1109/MTD.2015.7332620}, 
month={Oct},}

@article{vidal14,
	title={An approach to prioritize code smells for refactoring},
	author={Vidal, Santiago A and Marcos, Claudia and D{\'\i}az-Pace, J 
	Andr{\'e}s},
	journal={Automated Software Engineering},
	pages={1--32},
	year={2014},
	publisher={Springer}
}

@inproceedings{nugroho2011empirical,
  title={An empirical model of technical debt and interest},
  author={Nugroho, Ariadi and Visser, Joost and Kuipers, Tobias},
  booktitle={Proceedings of the 2nd Workshop on Managing Technical Debt},
  pages={1--8},
  year={2011},
  organization={ACM}
}

@inproceedings{guo2011portfolio,
  title={A portfolio approach to technical debt management},
  author={Guo, Yuepu and Seaman, Carolyn},
  booktitle={Proceedings of the 2nd Workshop on Managing Technical Debt},
  pages={31--34},
  year={2011},
  organization={ACM}
}

@inproceedings{zazworka2011prioritizing,
  title={Prioritizing design debt investment opportunities},
  author={Zazworka, Nico and Seaman, Carolyn and Shull, Forrest},
  booktitle={Proceedings of the 2nd Workshop on Managing Technical Debt},
  pages={39--42},
  year={2011},
  organization={ACM}
}

@inproceedings{zazworka2013case,
  title={A case study on effectively identifying technical debt},
  author={Zazworka, Nico and Sp{\'\i}nola, Rodrigo O and Vetro, Antonio and Shull, Forrest and Seaman, Carolyn},
  booktitle={Proceedings of the 17th International Conference on Evaluation and Assessment in Software Engineering},
  pages={42--47},
  year={2013},
  organization={ACM}
}

@book{mcconnell2004code,
  title={Code complete},
  author={McConnell, Steve},
  edition={2nd},
  year={2004},
  publisher={Pearson Education}
}

@misc{horror,
    author    = "Jeff Atwood",
    title     = "Code Smells",
    howpublished       = {"https://blog.codinghorror.com/code-smells/"},
    year = {2006}
}

 @techreport{iso14764,
   TITLE = "{ISO/IEC 14764:2006: Software Engineering -- Software Life Cycle Processes -- Maintenance}",
   PAGES = {1-44},
   YEAR = {2006},
   MONTH = {September},
   INSTITUTION = "{ISO/IEC}"
   }
   
@inproceedings{ge2012reconciling,
  title={Reconciling manual and automatic refactoring},
  author={Ge, Xi and DuBose, Quinton L and Murphy-Hill, Emerson},
  booktitle={2012 34th International Conference on Software Engineering (ICSE)},
  pages={211--221},
  year={2012},
  organization={IEEE}
}

@inproceedings{lee2013drag,
  title={Drag-and-drop refactoring: intuitive and efficient program transformation},
  author={Lee, Yun Young and Chen, Nicholas and Johnson, Ralph E},
  booktitle={Proceedings of the 2013 International Conference on Software Engineering},
  pages={23--32},
  year={2013},
  organization={IEEE Press}
}

@inproceedings{foster2012witchdoctor,
  title={WitchDoctor: IDE support for real-time auto-completion of refactorings},
  author={Foster, Stephen R and Griswold, William G and Lerner, Sorin},
  booktitle={Proceedings of the 34th International Conference on Software Engineering},
  pages={222--232},
  year={2012},
  organization={IEEE Press}
}

@inproceedings{ge2014manual,
  title={Manual refactoring changes with automated refactoring validation},
  author={Ge, Xi and Murphy-Hill, Emerson},
  booktitle={Proceedings of the 36th International Conference on Software Engineering},
  pages={1095--1105},
  year={2014},
  organization={ACM}
}

@inproceedings{kim2012field,
  title={A field study of refactoring challenges and benefits},
  author={Kim, Miryung and Zimmermann, Thomas and Nagappan, Nachiappan},
  booktitle={Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
  pages={50},
  year={2012},
  organization={ACM}
  }
  
@article{murphy2012we,
  title={How we refactor, and how we know it},
  author={Murphy-Hill, Emerson and Parnin, Chris and Black, Andrew P},
  journal={IEEE Transactions on Software Engineering},
  volume={38},
  number={1},
  pages={5--18},
  year={2012},
  publisher={IEEE}
}

@article{mkaouer2015many,
  title={Many-objective software remodularization using NSGA-III},
  author={Mkaouer, Wiem and Kessentini, Marouane and Shaout, Adnan and Koligheu, Patrice and Bechikh, Slim and Deb, Kalyanmoy and Ouni, Ali},
  journal={ACM Transactions on Software Engineering and Methodology (TOSEM)},
  volume={24},
  number={3},
  pages={17},
  year={2015},
  publisher={ACM}
}

@inproceedings{krishna16,
title={{Too Much Automation? The Bellwether Effect and Its Implications for Transfer Learning}},
author={Krishna, Rahul and Menzies, Tim and Fu, Wei},
year=2016,
booktitle="ASE'16"
}

@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{chawla2002smote,
  title={SMOTE: synthetic minority over-sampling technique},
  author={Chawla, Nitesh V. and Bowyer, Kevin W. and Hall, Lawrence O. and Kegelmeyer, W. Philip},
  journal={Journal of artificial intelligence research},
  volume={16},
  pages={321--357},
  year={2002}
}

 @inproceedings{Rahman2013,
abstract = {Defect prediction techniques could potentially help us to focus quality-assurance efforts on the most defect-prone files. Modern statistical tools make it very easy to quickly build and deploy prediction models. Software metrics are at the heart of prediction models; understanding how and especially why different types of metrics are effective is very important for successful model deployment. In this paper we analyze the applicability and efficacy of process and code metrics from several different perspectives. We build many prediction models across 85 releases of 12 large open source projects to address the performance, stability, portability and stasis of different sets of metrics. Our results suggest that code metrics, despite widespread use in the defect prediction literature, are generally less useful than process metrics for prediction. Second, we find that code metrics have high stasis; they don't change very much from release to release. This leads to stagnation in the prediction models, leading to the same files being repeatedly predicted as defective; unfortunately, these recurringly defective files turn out to be comparatively less defect-dense. {\textcopyright} 2013 IEEE.},
author = {Rahman, Foyzur and Devanbu, Premkumar},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2013.6606589},
isbn = {9781467330763},
issn = {02705257},
pages = {432--441},
title = {{How, and why, process metrics are better}},
year = {2013}
}

@article{Ma2012,
abstract = {Context: Software defect prediction studies usually built models using within-company data, but very few focused on the prediction models trained with cross-company data. It is difficult to employ these models which are built on the within-company data in practice, because of the lack of these local data repositories. Recently, transfer learning has attracted more and more attention for building classifier in target domain using the data from related source domain. It is very useful in cases when distributions of training and test instances differ, but is it appropriate for cross-company software defect prediction? Objective: In this paper, we consider the cross-company defect prediction scenario where source and target data are drawn from different companies. In order to harness cross company data, we try to exploit the transfer learning method to build faster and highly effective prediction model. Method: Unlike the prior works selecting training data which are similar from the test data, we proposed a novel algorithm called Transfer Naive Bayes (TNB), by using the information of all the proper features in training data. Our solution estimates the distribution of the test data, and transfers cross-company data information into the weights of the training data. On these weighted data, the defect prediction model is built. Results: This article presents a theoretical analysis for the comparative methods, and shows the experiment results on the data sets from different organizations. It indicates that TNB is more accurate in terms of AUC (The area under the receiver operating characteristic curve), within less runtime than the state of the art methods. Conclusion: It is concluded that when there are too few local training data to train good classifiers, the useful knowledge from different-distribution training data on feature level may help. We are optimistic that our transfer learning method can guide optimal resource allocation strategies, which may reduce software testing cost and increase effectiveness of software testing process. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Ma, Ying and Luo, Guangchun and Zeng, Xue and Chen, Aiguo},
doi = {10.1016/j.infsof.2011.09.007},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Different distribution,Machine learning,Naive Bayes,Software defect prediction,Transfer learning},
number = {3},
pages = {248--256},
title = {{Transfer learning for cross-company software defect prediction}},
volume = {54},
year = {2012}
}
@article{Chen2015,
abstract = {Context: Software defect prediction has been widely studied based on various machine-learning algorithms. Previous studies usually focus on within-company defects prediction (WCDP), but lack of training data in the early stages of software testing limits the efficiency of WCDP in practice. Thus, recent research has largely examined the cross-company defects prediction (CCDP) as an alternative solution. Objective: However, the gap of different distributions between cross-company (CC) data and withincompany (WC) data usually makes it difficult to build a high-quality CCDP model. In this paper, a novel algorithm named Double Transfer Boosting (DTB) is introduced to narrow this gap and improve the performance of CCDP by reducing negative samples in CC data. Method: The proposed DTB model integrates two levels of data transfer: first, the data gravitation method reshapes the whole distribution of CC data to fit WC data. Second, the transfer boosting method employs a small ratio of labeled WC data to eliminate negative instances in CC data. Results: The empirical evaluation was conducted based on 15 publicly available datasets. CCDP experiment results indicated that the proposed model achieved better overall performance than compared CCDP models. DTB was also compared to WCDP in two different situations. Statistical analysis suggested that DTB performed significantly better than WCDP models trained by limited samples and produced comparable results to WCDP with sufficient training data. Conclusions: DTB reforms the distribution of CC data from different levels to improve the performance of CCDP, and experimental results and analysis demonstrate that it could be an effective model for early software defects detection.},
author = {Chen, Lin and Fang, Bin and Shang, Zhaowei and Tang, Yuanyan},
doi = {10.1016/j.infsof.2015.01.014},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Cross-company defects prediction,Software fault prediction,Transfer learning},
number = {1},
pages = {67--77},
title = {{Negative samples reduction in cross-company software defects prediction}},
volume = {62},
year = {2015}
}
@article{Minku2014,
abstract = {Previous works using Cross-Company (CC) data for making Within-Company (WC) Software Effort Estimation (SEE) try to use CC data or models directly to provide predic- tions in the WC context. So, these data or models are only helpful when they match the WC context well. When they do not, a fair amount of WC training data, which are usu- ally expensive to acquire, are still necessary to achieve good performance. We investigate how to make best use of CC data, so that we can reduce the amount of WC data while maintaining or improving performance in comparison toWC SEE models. This is done by proposing a new framework to learn the relationship between CC and WC projects ex- plicitly, allowing CC models to be mapped to the WC con- text. Such mapped models can be useful even when the CC models themselves do not match the WC context directly. Our study shows that a new approach instantiating this framework is able not only to use substantially lessWC data than a corresponding WC model, but also to achieve similar/better performance. This approach can also be used to provide insight into the behaviour of a company in comparison to others.},
author = {Minku, Leandro L and Yao, Xin},
doi = {10.1145/2568225.2568228},
isbn = {9781450327565},
journal = {36th International Conference on Software Engineering (ICSE 2014)},
keywords = {cross-company learning,ensembles of learning machines,learning,online learning,or hard copies of,part or all of,permission to make digital,software effort estimation,this work for,transfer},
pages = {446--456},
title = {{How to Make Best Use of Cross-Company Data in Software Effort Estimation ? Categories and Subject Descriptors}},
year = {2014}
}
@inproceedings{Peters2013,
abstract = {How can we find data for quality prediction? Early in the life cycle, projects may lack the data needed to build such predictors. Prior work assumed that relevant training data was found nearest to the local project. But is this the best approach? This paper introduces the Peters filter which is based on the following conjecture: When local data is scarce, more information exists in other projects. Accordingly, this filter selects training data via the structure of other projects. To assess the performance of the Peters filter, we compare it with two other approaches for quality prediction. Within-company learning and cross-company learning with the Burak filter (the state-of-the-art relevancy filter). This paper finds that: 1) within-company predictors are weak for small data-sets; 2) the Peters filter+cross-company builds better predictors than both within-company and the Burak filter+cross-company; and 3) the Peters filter builds 64{\%} more useful predictors than both within-company and the Burak filter+cross-company approaches. Hence, we recommend the Peters filter for cross-company learning. {\textcopyright} 2013 IEEE.},
author = {Peters, Fayola and Menzies, Tim and Marcus, Andrian},
booktitle = {IEEE International Working Conference on Mining Software Repositories},
doi = {10.1109/MSR.2013.6624057},
isbn = {9781467329361},
issn = {21601852},
keywords = {Cross company,Data mining,Defect prediction},
pages = {409--418},
title = {{Better cross company defect prediction}},
year = {2013}
}
@article{Kocaguneli2015,
abstract = {When projects lack sufficient local data to make predictions, they try to transfer information from other projects. How can we best support this process? In the field of software engineering, transfer learning has been shown to be effective for defect prediction. This paper checks whether it is possible to build transfer learners for software effort estimation. We use data on 154 projects from 2 sources to investigate transfer learning between different time intervals and 195 projects from 51 sources to provide evidence on the value of transfer learning for traditional cross-company learning problems. We find that the same transfer learning method can be useful for transfer effort estimation results for the cross-company learning problem and the cross-time learning problem. It is misguided to think that: (1) Old data of an organization is irrelevant to current context or (2) data of another organization cannot be used for local solutions. Transfer learning is a promising research direction that transfers relevant cross data between time intervals and domains.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Mendes, Emilia},
doi = {10.1007/s10664-014-9300-5},
issn = {15737616},
journal = {Empirical Software Engineering},
keywords = {Data mining,Effort estimation,Transfer learning,k-NN},
number = {3},
pages = {813--843},
title = {{Transfer learning in effort estimation}},
volume = {20},
year = {2015}
}
@inproceedings{Nam2013,
abstract = {Many software defect prediction approaches have been proposed and most are effective in within-project prediction settings. However, for new projects or projects with limited training data, it is desirable to learn a prediction model by using sufficient training data from existing source projects and then apply the model to some target projects (cross-project defect prediction). Unfortunately, the performance of cross-project defect prediction is generally poor, largely because of feature distribution differences between the source and target projects. In this paper, we apply a state-of-the-art transfer learning approach, TCA, to make feature distributions in source and target projects similar. In addition, we propose a novel transfer defect learning approach, TCA+, by extending TCA. Our experimental results for eight open-source projects show that TCA+ significantly improves cross-project prediction performance. {\textcopyright} 2013 IEEE.},
author = {Nam, Jaechang and Pan, Sinno Jialin and Kim, Sunghun},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2013.6606584},
isbn = {9781467330763},
issn = {02705257},
keywords = {cross-project defect prediction,empirical software engineering,transfer learning},
pages = {382--391},
title = {{Transfer defect learning}},
year = {2013}
}
@inproceedings{Minku2012,
abstract = {Background: There has been a long debate in the software engineering literature concerning how useful cross-company (CC) data are for software effort estimation (SEE) in comparison to within-company (WC) data. Studies indicate that models trained on CC data obtain either similar or worse performance than models trained solely on WC data. Aims: We aim at investigating if CC data could help to increase performance and under what conditions. Method: The work concentrates on the fact that SEE is a class of online learning tasks which operate in changing environments, even though most work so far has neglected that. We conduct an analysis based on the performance of different approaches considering CC and WC data. These are: (1) an approach not designed for changing environments, (2) approaches designed for changing environments and (3) a new online learning approach able to identify when CC data are helpful or detrimental. Results: Interesting features of data sets commonly used in the SEE literature are revealed, showing that different subsets of CC data can be beneficial or detrimental depending on the moment in time. The newly proposed approach is able to benefit from that, successfully using CC data to improve performance over WC models. Conclusions: This work not only shows that CC data can help to increase performance for SEE tasks, but also demonstrates that the online nature of software prediction tasks should be exploited, being an important issue to be considered in the future.},
author = {Minku, Leandro L. and Yao, Xin},
booktitle = {Proceedings of the 8th International Conference on Predictive Models in Software Engineering - PROMISE '12},
doi = {10.1145/2365324.2365334},
isbn = {9781450312417},
keywords = {bles of learning machines,chronological split,concept drift,cross-company estimation mod-,els,ensem-,online learning,software effort estimation},
pages = {69--78},
title = {{Can cross-company data improve performance in software effort estimation?}},
url = {http://dl.acm.org/citation.cfm?doid=2365324.2365334},
year = {2012}
}
@article{Turhan2009,
abstract = {We propose a practical defect prediction approach for companies that do not track defect related data. Specifically, we investigate the applicability of cross-company (CC) data for building localized defect predictors using static code features. Firstly, we analyze the conditions, where CC data can be used as is. These conditions turn out to be quite few. Then we apply principles of analogy-based learning (i.e. nearest neighbor (NN) filtering) to CC data, in order to fine tune these models for localization. We compare the performance of these models with that of defect predictors learned from within-company (WC) data. As expected, we observe that defect predictors learned from WC data outperform the ones learned from CC data. However, our analyses also yield defect predictors learned from NN-filtered CC data, with performance close to, but still not better than, WC data. Therefore, we perform a final analysis for determining the minimum number of local defect reports in order to learn WC defect predictors. We demonstrate in this paper that the minimum number of data samples required to build effective defect predictors can be quite small and can be collected quickly within a few months. Hence, for companies with no local defect data, we recommend a two-phase approach that allows them to employ the defect prediction process instantaneously. In phase one, companies should use NN-filtered CC data to initiate the defect prediction process and simultaneously start collecting WC (local) data. Once enough WC data is collected (i.e. after a few months), organizations should switch to phase two and use predictors learned from WC data.},
author = {Turhan, Burak and Menzies, Tim and Bener, Ayşe B. and {Di Stefano}, Justin},
doi = {10.1007/s10664-008-9103-7},
isbn = {1382-3256},
issn = {13823256},
journal = {Empirical Software Engineering},
keywords = {Cross-company,Defect prediction,Learning,Metrics (product metrics),Nearest-neighbor filtering,Within-company},
number = {5},
pages = {540--578},
title = {{On the relative value of cross-company and within-company data for defect prediction}},
volume = {14},
year = {2009}
}
@article{Ma2011,
abstract = {Traditional machine learning works well within company defect prediction. Unlike these works, we consider the scenario where source and target data are drawn from different companies, recently referred to as cross-company defect prediction. In this paper, we proposed a novel algorithm based on transfer method, called Transfer Naive Bayes (TNB). Our solution transferred the information of test data to the weights of the training data. The theoretical analysis and experiment results indicate that our algorithm is able to get more accurate result within less runtime cost than the state of the art algorithm.},
author = {Ma, Ying and Luo, Guangchun and Li, Jiong and Chen, Aiguo},
doi = {10.1109/ICCPS.2011.6092261},
isbn = {978-1-4577-0601-1},
journal = {2011 International Conference on Computational Problem-Solving (ICCP)},
pages = {610--613},
title = {{Software defect prediction using transfer method}},
year = {2011}
}


@article{osei04,
  title={Evaluation of decision trees: a multi-criteria approach},
  author={Osei-Bryson, Kweku-Muata},
  journal={Computers \& Operations Research},
  volume={31},
  number={11},
  pages={1933--1945},
  year={2004},
  publisher={Elsevier}
}

@article{me16phase,
title="Are Delayed Issues Harder to Resolve?",
author="T. Menzies and W. Nichols and F. Shull  and L. Layman",
year=2016,
  journal={Empirical Software Engineering (accepted)},
note="Online at https://goo.gl/MZ0h6H."
}

@inproceedings{krishna2015actionable,
  title={Actionable= Cluster+ Contrast?},
  author={Krishna, Rahul and Menzies, Tim},
  booktitle={2015 30th IEEE/ACM International Conference on Automated Software Engineering Workshop (ASEW)},
  pages={14--17},
  year={2015},
  organization={IEEE}
}

@inproceedings{me12d,
abstract = {Abstract—Data miners can infer rules showing how to improve either (a) the effort estimates of a project or (b) the defect predictions of a software module. Such studies often exhibit conclusion instability regarding what is the most effective action for different projects or modules. This instability can be explained by data heterogeneity. We show that effort and defect data contain many local regions with markedly different properties to the global space. In other words, what appears to be useful in a global context is often irrelevant for particular local contexts. This result raises questions about the generality of conclusions from empirical SE. At the very least, SE researchers should test if their supposedly general conclusions are valid within subsets of their data. At the very most, empirical SE should become a search for local regions with similar properties (and conclusions should be constrained to just those regions).},
author = {Menzies, Tim and Butcher, Andrew and Marcus, Andrian and Zimmermann, Thomas and Cok, David},
booktitle = {2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011)},
doi = {10.1109/ASE.2011.6100072},
file = {:Users/rkrsn/Documents/Mendeley Desktop/Menzies et al. - Local vs. global models for effort estimation and defect prediction.pdf:pdf},
isbn = {978-1-4577-1639-3},
keywords = {Data mining,I,defect/effort estimation,empirical SE.,validation},
mendeley-groups = {ASE 2015 Lit},
month = {nov},
pages = {343--351},
publisher = {IEEE},
title = {{Local vs. global models for effort estimation and defect prediction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6100072},
year = {2011}
}
@misc{sq15,
title={Sonar{Q}ube: Open Source Quality Management},
author={A. Campbell},
year={2015},
note="Website: tiny.cc/2q4z9x"
}

@BOOK {Kerievsky2005,
    author    = "Joshua Kerievsky",
    title     = "Refactoring to Patterns",
    publisher = "Addison-Wesly Professional",
    year      = "2005"
}

@inproceedings{george2003initial,
  title={An initial investigation of test driven development in industry},
  author={George, Boby and Williams, Laurie},
  booktitle={Proceedings of the 2003 ACM symposium on Applied computing},
  pages={1135--1139},
  year={2003},
  organization={ACM}
}

@inproceedings{williams2003test,
  title={Test-driven development as a defect-reduction practice},
  author={Williams, Laurie and Maximilien, E Michael and Vouk, Mladen},
  booktitle={Software Reliability Engineering, 2003. ISSRE 2003. 14th International Symposium on},
  pages={34--45},
  year={2003},
  organization={IEEE}
}

@book{beck2003test,
  title={Test-driven development: by example},
  author={Beck, Kent},
  year={2003},
  publisher={Addison-Wesley Professional}
}

@article{janzen05,
 author = {Janzen, David and Saiedian, Hossein},
 title = {Test-Driven Development: Concepts, Taxonomy, and Future Direction},
 journal = {Computer},
 issue_date = {September 2005},
 volume = {38},
 number = {9},
 month = sep,
 year = {2005},
 issn = {0018-9162},
 pages = {43--50},
 numpages = {8},
 url = {http://dx.doi.org/10.1109/MC.2005.314},
 doi = {10.1109/MC.2005.314},
 acmid = {1092262},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
 keywords = {extreme programming, iterative software development, iterative software development, software development, test-driven development, extreme programming, software development, test-driven development},
} 


@book{Lanza2006,
author = {Lanza, Michele and Marinescu, Radu},
mendeley-groups = {References},
pages = {207},
publisher = {Springer Verlag},
title = {{Object-Oriented Metrics in Practice: Using Software Metrics to Characterize, Evaluate, and Improve the Design of Object-Oriented Systems}},
year = {2006}
}

@ARTICLE{Sjoberg2013, 
author={Sjoberg, D.I.K. and Yamashita, A. and Anda, B.C.D. and Mockus, A. and Dyba, T.}, 
journal={Software Engineering, IEEE Transactions on}, 
title={Quantifying the Effect of Code Smells on Maintenance Effort}, 
year={2013}, 
month={Aug}, 
volume={39}, 
number={8}, 
pages={1144-1156}, 
keywords={Java;regression analysis;software maintenance;Eclipse IDE plug-in;Java files;Java systems;code size reduction;code smell effect quantification;code smell refactoring;file properties;file size;maintainable code;maintenance effort;maintenance tasks;refused bequest;regression analysis;Context;Electronic mail;Java;Maintenance engineering;Software;Surgery;Time measurement;Maintainability;code churn;object-oriented design;product metrics}, 
doi={10.1109/TSE.2012.89}, 
ISSN={0098-5589},}


@INPROCEEDINGS{Yamashita2013, 
author={Yamashita, A. and Moonen, L.}, 
booktitle={Reverse Engineering (WCRE), 2013 20th Working Conference on}, 
title={Do developers care about code smells? An exploratory survey}, 
year={2013}, 
month={Oct}, 
pages={242-251}, 
keywords={program diagnostics;software maintenance;software quality;code decay;code quality;code smell detection;code smell removal;software maintenance problems;Encoding;Feature extraction;Java;Maintenance engineering;Programming;Software;code analysis tools;code smell detection;code smells;maintainability;refactoring;survey;usability}, 
doi={10.1109/WCRE.2013.6671299},}



@article{boehm01,
  author =	 "Barry Boehm and Victor R. Basili",
  title =	 "Software Defect Reduction Top 10 list",
  journal =	 "IEEE Software",
  month =	 "January",
  pages =	 "135-137",
  year =	 2001
}

@inproceedings{erni96,
  title={Applying design-metrics to object-oriented frameworks},
  author={Erni, Karin and Lewerentz, Claus},
  booktitle={Software Metrics Symposium, 1996., Proceedings of the 3rd International},
  pages={64--74},
  year={1996},
  organization={IEEE}
}


@misc{aschwanden10,
  author="Christie Aschwanden",
  year=2010,
  title = {{Convincing the Public to Accept New Medical Guidelines}},
  howpublished = {\url{http://goo.gl/RT6SK7}},
  note = {FiveThiryEight.com. Accessed: 2015-02-10}
}


@article{prasad13,
title = "A Decade of Reversal: An Analysis of 146 Contradicted Medical Practices ",
journal = "Mayo Clinic Proceedings ",
volume = "88",
number = "8",
pages = "790 - 798",
year = "2013",
note = "",
issn = "0025-6196",
doi = "http://dx.doi.org/10.1016/j.mayocp.2013.05.012",
url = "http://www.sciencedirect.com/science/article/pii/S0025619613004059",
author = "Vinay Prasad and Andrae Vandross and Caitlin Toomey and Michael Cheung and Jason Rho and Steven Quinn and Satish Jacob Chacko and Durga Borkar and Victor Gall and Senthil Selvaraj and Nancy Ho and Adam Cifu"
}


@misc{aschwanden15,
  author="Christie Aschwanden",
  year=2015,
  title = {{Your Brain Is Primed To Reach False Conclusions}},
  howpublished = {\url{http://goo.gl/OO3B7s}},
  note = {FiveThirtyEight.com. Accessed: 2015-02-10}
}

 
@article{dunsmore88,
  title =	 "Evidence Supports some Truisms, Belies Others. (Some
                  Empirical Results concerning Software Development)",
  journal =	 "IEEE Software",
  author =	 "Hubert E. Dunsmore",
  month =	 "May",
  year =	 1988,
  pages =	 "96-99"
}

@article {bender99,
author = {Bender, Ralf},
title = {Quantitative Risk Assessment in Epidemiological Studies Investigating Threshold Effects},
journal = {Biometrical Journal},
volume = {41},
number = {3},
publisher = {WILEY-VCH Verlag Berlin GmbH},
issn = {1521-4036},
url = {http://dx.doi.org/10.1002/(SICI)1521-4036(199906)41:3<305::AID-BIMJ305>3.0.CO;2-Y},
doi = {10.1002/(SICI)1521-4036(199906)41:3<305::AID-BIMJ305>3.0.CO;2-Y},
pages = {305--319},
keywords = {Benchmark values, Binary data, Epidemiological studies, Logistic regression, Quantitative risk assessment, Threshold model},
year = {1999},
}


@article{Dijkstra68,
 author = {Dijkstra, Edsger W.},
 title = {Letters to the Editor: Go to Statement Considered Harmful},
 journal = {Commun. ACM},
 issue_date = {March 1968},
 volume = {11},
 number = {3},
 month = mar,
 year = {1968},
 issn = {0001-0782},
 pages = {147--148},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/362929.362947},
 doi = {10.1145/362929.362947},
 acmid = {362947},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {alternative clause, branch instruction, conditional clause, go to statement, jump instruction, program intelligibility, program sequencing, repetitive clause},
} 

@inproceedings{mei15,
 author = {Nagappan, Meiyappan and Robbes, Romain and Kamei, Yasutaka and Tanter, \'{E}ric and McIntosh, Shane and Mockus, Audris and Hassan, Ahmed E.},
 title = {An Empirical Study of Goto in C Code from GitHub Repositories},
 booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
 series = {ESEC/FSE 2015},
 year = {2015},
 isbn = {978-1-4503-3675-8},
 location = {Bergamo, Italy},
 pages = {404--414},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/2786805.2786834},
 doi = {10.1145/2786805.2786834},
 acmid = {2786834},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Dijkstra, Empirical SE, Github, Use of goto statements},
}  

@article{aha91,
  title={Instance-based learning algorithms},
  author={Aha, David W and Kibler, Dennis and Albert, Marc K},
  journal={Machine learning},
  volume={6},
  number={1},
  pages={37--66},
  year={1991},
  publisher={Springer}
}

@article{khomh12,
  title={An exploratory study of the impact of antipatterns on class change-and fault-proneness},
  author={Khomh, Foutse and Di Penta, Massimiliano and Gu{\'e}h{\'e}neuc, Yann-Ga{\"e}l and Antoniol, Giuliano},
  journal={Empirical Software Engineering},
  volume={17},
  number={3},
  pages={243--275},
  year={2012},
  publisher={Springer}
}
@article{fab15_1,
  title={Anti-Pattern Detection: Methods, Challenges, and Open Issues.},
  author={Palomba, Fabio and De Lucia, Andrea and Bavota, Gabriele and Oliveto, Rocco},
  journal={Advances in Computers},
  volume={95},
  pages={201--238},
  year={2015}
}
@inproceedings{chatzigeorgiou10,
  title={Investigating the evolution of bad smells in object-oriented code},
  author={Chatzigeorgiou, Alexander and Manakos, Anastasios},
  booktitle={Quality of Information and Communications Technology (QUATIC), 2010 Seventh International Conference on the},
  pages={106--115},
  year={2010},
  organization={IEEE}
}
@article{darcy05,
  title={O{O} metrics in practice},
  author={Darcy, David P and Kemerer, Chris F},
  journal={Software, IEEE},
  volume={22},
  number={6},
  pages={17--19},
  year={2005},
  publisher={IEEE}
}

@inproceedings{arcoverde11,
  title={Understanding the longevity of code smells: preliminary results of an explanatory survey},
  author={Arcoverde, Roberta and Garcia, Alessandro and Figueiredo, Eduardo},
  booktitle={Proceedings of the 4th Workshop on Refactoring Tools},
  pages={33--36},
  year={2011},
  organization={ACM}
}
@ARTICLE{Shatnawi10, 
author={R. Shatnawi}, 
journal={IEEE Transactions on Software Engineering}, 
title={A Quantitative Investigation of the Acceptable Risk Levels of Object-Oriented Metrics in Open-Source Systems}, 
year={2010}, 
volume={36}, 
number={2}, 
pages={216-225}, 
keywords={decision trees;object-oriented programming;public domain software;software fault tolerance;software maintenance;software metrics;statistical analysis;Chidamber and Kemerer metrics;Eclipse project version 2.1;data distribution parameters;decision trees;logistic regression;object-oriented metrics;open source systems;software complexity;software design;software metrics;statistical model;threshold values;CK metrics;Object-oriented programming;open-source software.;product metrics;threshold values}, 
doi={10.1109/TSE.2010.9}, 
ISSN={0098-5589}, 
month={March},}

@inproceedings{Tufano2015,
author = {Tufano, Michele and Palomba, Fabio and Bavota, Gabriele and Oliveto, Rocco and {Di Penta}, Massimiliano and {De Lucia}, Andrea and Poshyvanyk, Denys},
booktitle = {2015 IEEE/ACM 37th IEEE Int. Conf. Softw. Eng.},
doi = {10.1109/ICSE.2015.59},
file = {:Users/rkrsn/Documents/Mendeley Desktop/Tufano et al. - When and Why Your Code Starts to Smell Bad - 2015.pdf:pdf},
isbn = {978-1-4799-1934-5},
mendeley-groups = {ANTI PATTERNS},
month = {May},
pages = {403--414},
publisher = {IEEE},
title = {{When and Why Your Code Starts to Smell Bad}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7194592},
year = {2015}
}
@article{moha10,
  title={DECOR: A method for the specification and detection of code and design smells},
  author={Moha, Naouel and Gueheneuc, Yann-Gael and Duchien, Laurence and Le Meur, Anne-Francoise},
  journal={Software Engineering, IEEE Transactions on},
  volume={36},
  number={1},
  pages={20--36},
  year={2010},
  publisher={IEEE}
}


@INPROCEEDINGS{bosu13, 
author={A. Bosu and J. C. Carver}, 
booktitle={Empirical Software Engineering and Measurement, 2013 ACM / IEEE International Symposium on}, 
title={Impact of Peer Code Review on Peer Impression Formation: A Survey}, 
year={2013}, 
pages={133-142}, 
month={Oct},}

@inproceedings{fi,
	author = {Usama M. Fayyad and Keki B. Irani},
	booktitle = {Thirteenth International Joint Conference on Articial Intelligence},
	pages = {1022-1027},
	publisher = {Morgan Kaufmann Publishers},
	title = {Multi-interval discretization of continuous valued attributes for classification learning},
	volume = {2},
	year = {1993}
}


@book{fowler99,
 title = {Refactoring: Improving the Design of Existing Code},
 year = {1999}, 
 author ={M. Fowler and K. Beck and J.  Brant and W. Opdyke, and D Roberts},
 publisher = {Addison-Wesley Longman},
 address = {Boston, MA, USA}, 
} 
@article{hermans15,
  title={Detecting and refactoring code smells in spreadsheet formulas},
  author={Hermans, Felienne and Pinzger, Martin and van Deursen, Arie},
  journal={Empirical Software Engineering},
  volume={20},
  number={2},
  pages={549--575},
  year={2015},
  publisher={Springer}
}
@inproceedings{Alves2010,
author = {Alves, Tiago L. and Ypma, Christiaan and Visser, Joost},
booktitle = {2010 IEEE Int. Conf. Softw. Maint.},
doi = {10.1109/ICSM.2010.5609747},
isbn = {978-1-4244-8630-4},
issn = {10636773},
mendeley-groups = {OO Metric Thresholds},
month = {sep},
pages = {1--10},
publisher = {IEEE},
title = {{Deriving metric thresholds from benchmark data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5609747},
year = {2010}
}

@article{lehman79,
  title={On understanding laws, evolution, and conservation in the large-program life cycle},
  author={Lehman, Meir M},
  journal={Journal of Systems and Software},
  volume={1},
  pages={213--221},
  year={1979},
  publisher={Elsevier}
}
@book{fowler09,
  title={Refactoring: improving the design of existing code},
  author={Fowler, Martin},
  year={2009},
  publisher={Pearson Education India}
}
@article{brown98,
  title={AntiPatterns: refactoring software, architectures, and projects in crisis},
  author={Brown, William H and Malveau, Raphael C and Mowbray, Thomas J},
  year={1998},
  publisher={Wiley}
}
@inproceedings{abbes11,
  title={An empirical study of the impact of two antipatterns, blob and spaghetti code, on program comprehension},
  author={Abbes, Marwen and Khomh, Foutse and Gueheneuc, Yann-Gael and Antoniol, Giuliano},
  booktitle={Software Maintenance and Reengineering (CSMR), 2011 15th European Conference on},
  pages={181--190},
  year={2011},
  organization={IEEE}
}
@article{khomh12,
  title={An exploratory study of the impact of antipatterns on class change-and fault-proneness},
  author={Khomh, Foutse and Di Penta, Massimiliano and Gu{\'e}h{\'e}neuc, Yann-Ga{\"e}l and Antoniol, Giuliano},
  journal={Empirical Software Engineering},
  volume={17},
  number={3},
  pages={243--275},
  year={2012},
  publisher={Springer}
}
@article{yamashita2013code,
  title={Code smells as system-level indicators of maintainability: An empirical study},
  author={Yamashita, Aiko and Counsell, Steve},
  journal={Journal of Systems and Software},
  volume={86},
  number={10},
  pages={2639--2653},
  year={2013},
  publisher={Elsevier}
}

@inproceedings{yama13,
  title={Exploring the impact of inter-smell relations on software maintainability: An empirical study},
  author={Yamashita, Aiko and Moonen, Leon},
  booktitle={Proceedings of the 2013 International Conference on Software Engineering},
  pages={682--691},
  year={2013},
  organization={IEEE Press}
}

@incollection{boussaa13,
  title={Competitive coevolutionary code-smells detection},
  author={Boussaa, Mohamed and Kessentini, Wael and Kessentini, Marouane and Bechikh, Slim and Chikha, Soukeina Ben},
  booktitle={Search Based Software Engineering},
  pages={50--65},
  year={2013},
  publisher={Springer}
}
@article{tsantalis09,
  title={Identification of move method refactoring opportunities},
  author={Tsantalis, Nikolaos and Chatzigeorgiou, Alexander},
  journal={Software Engineering, IEEE Transactions on},
  volume={35},
  number={3},
  pages={347--367},
  year={2009},
  publisher={IEEE}
}
@article{moha2010,
  title={DECOR: A method for the specification and detection of code and design smells},
  author={Moha, Naouel and Gueheneuc, Yann-Gael and Duchien, Laurence and Le Meur, Anne-Francoise},
  journal={Software Engineering, IEEE Transactions on},
  volume={36},
  number={1},
  pages={20--36},
  year={2010},
  publisher={IEEE}
}
@article{barr15,
  title={The oracle problem in software testing: A survey},
  author={Barr, Earl T and Harman, Mark and McMinn, Phil and Shahbaz, Muzammil and Yoo, Shin},
  journal={Software Engineering, IEEE Transactions on},
  volume={41},
  number={5},
  pages={507--525},
  year={2015},
  publisher={IEEE}
}

@article{boehm2003using,
  title={Using risk to balance agile and plan-driven methods},
  author={Boehm, Barry and Turner, Richard},
  journal={Computer},
  number={6},
  pages={57--66},
  year={2003},
  publisher={IEEE}
}

@book{boehm2003balancing,
  title={Balancing agility and discipline: A guide for the perplexed},
  author={Boehm, Barry and Turner, Richard},
  year={2003},
  publisher={Addison-Wesley Professional}
}

@inproceedings{port2008,
  title={Using simulation to investigate requirements prioritization strategies},
  author={Port, Daniel and Olkov, Alexy and Menzies, Tim},
  booktitle={Proceedings of the 2008 23rd IEEE/ACM International Conference on Automated Software Engineering},
  pages={268--277},
  year={2008},
  organization={IEEE Computer Society}
}

@ARTICLE{Sjoberg13, 
author={Sj\"oberg, D.I.K. and Yamashita, A. and Anda, B.C.D. and Mockus, A. and Dyba, T.}, 
journal={Software Engineering, IEEE Transactions on}, 
title={Quantifying the Effect of Code Smells on Maintenance Effort}, 
year={2013}, 
volume={39}, 
number={8}, 
pages={1144-1156}, 
keywords={Java;regression analysis;software maintenance;Eclipse IDE plug-in;Java files;Java systems;code size reduction;code smell effect quantification;code smell refactoring;file properties;file size;maintainable code;maintenance effort;maintenance tasks;refused bequest;regression analysis;Context;Electronic mail;Java;Maintenance engineering;Software;Surgery;Time measurement;Maintainability;code churn;object-oriented design;product metrics}, 
doi={10.1109/TSE.2012.89}, 
ISSN={0098-5589}, 
month={Aug},}

@inproceedings{krishna15,
  title="Actionable = Cluster + Constrast?",
  author="Krishna, Rahul and Menzies, Tim",
  year="\textit{ACTION'15: an ASE'15 workshop}, 2015",
  }
@article{Dhama199565,
title = "Quantitative models of cohesion and coupling in software ",
journal = "Journal of Systems and Software ",
volume = "29",
number = "1",
pages = "65 - 74",
year = "1995",
note = "Oregon Metric Workshop ",
issn = "0164-1212",
doi = "http://dx.doi.org/10.1016/0164-1212(94)00128-A",
url = "http://www.sciencedirect.com/science/article/pii/016412129400128A",
author = "Harpal Dhama",
abstract = "Our project goal is to specify, implement, and verify quantitative models for measuring cohesion and coupling (C &amp; C) in software modules. This article is our project interim report on the specification of the C &amp; C quantitative models and preliminary verification effort. To quantify cohesion, we subdivided it into four categories and then quantified each category. Coupling is subdivided into four categories, followed by the quantification of each category. Although the C &amp; C concepts are applicable to any procedural language such as FORTRAN, PASCAL, or Ada, we chose to apply the C &amp; C formulas to Ada programs. We have hand-calculated C &amp; C values for a number of programs, but here we report and discuss in detail only a typical result of our calculations obtained by applying the C &amp; C formulas to two different implementations of an algorithm. We have found that the formulas are sensitive enough to distinguish between the two implementations, and the obtained quantitative values agree with the qualitative assessment of the implementations. "
}

@article{boley98,
	Author = {Boley, Daniel},
	Journal = {Data Min. Knowl. Discov.},
	Month = {December},
	Number = 4,
	Pages = {325--344},
	Title = {Principal Direction Divisive Partitioning},
	Volume = 2,
	Year = 1998}


@inproceedings{Faloutsos1995,
	Author = {Faloutsos, Christos and Lin, King-Ip},
	Booktitle = {Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data},
	Isbn = {0-89791-731-6},
	Location = {San Jose, California, United States},
	Pages = {163--174},
	Title = {{FastMap}: a fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets},
	Year = 1995}

@ARTICLE{jorgensen09,
  author =	 {J{\o}rgensen, Magne and Gruschke, Tanja M.},
  journal =	 {Software Engineering, IEEE Transactions on},
  title =	 {The Impact of Lessons-Learned Sessions on Effort
                  Estimation and Uncertainty Assessments},
  year =	 2009,
  month =	 {May-June },
  volume =	 35,
  number =	 3,
  pages =	 {368 -383},
}

@inproceedings{passos11,
  title =	 "Analyzing the Impact of Beliefs in Software Project
                  Practices",
  author =	 "Carol Passos and Ana Paula Braun and Daniela
                  S. Cruzes and Manoel Mendonca",
  year =	 2011,
  booktitle =	 "ESEM'11"
}


@mastersthesis{div14,
  title="Exploring Essential content of Defect Prediction 
         and Effort Estimation through Data Reduction",
  year=2014,
  author="Divya Ganesan",
  school="Computer Science, West Virginia University"
 }
 

@article{kocaguneli2014transfer,
  title={Transfer learning in effort estimation},
  author={Kocaguneli, Ekrem and Menzies, Tim and Mendes, Emilia},
  journal={Empirical Software Engineering},
  pages={1--31},
  year={2014},
  publisher={Springer US}
}

@book{quinlan92,
  title =	 "C4.5: Programs for Machine Learning",
  author =	 "R. Quinlan",
  year =	 1992,
  publisher =	 "Morgan Kaufman",
  note =	 "ISBN: 1558602380"
}
@book{breiman84,
  author =	 "L. Breiman and J. H. Friedman and R. A. Olshen and
                  C. J. Stone",
  title =	 "Classification and Regression Trees",
  institution =	 "Wadsworth International, Monterey, CA",
  year =	 1984,
  annote =	 "cart algorithm"
}
@inproceedings{menzies12a,
  author="T. Menzies and T. Zimmermann",
  title="Goldfish Bowl Panel: Software Development Analytics",
  booktitle="ICSE'12",
  pages="1032-1033"
}

@incollection{rob14,
  author    = {Martin P. Robillard and
               Robert J. Walker},
  title     = {An Introduction to Recommendation Systems in Software Engineering},
  booktitle = {Recommendation Systems in Software Engineering},
  pages     = {1--11},
  year      = {2014},
  crossref  = {DBLP:books/sp/rsse2014},
  url       = {http://dx.doi.org/10.1007/978-3-642-45135-5_1},
  doi       = {10.1007/978-3-642-45135-5_1},
  timestamp = {Mon, 08 Sep 2014 14:46:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/books/sp/rsse14/RobillardW14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@book{DBLP:books/sp/rsse2014,
  editor    = {Martin P. Robillard and
               Walid Maalej and
               Robert J. Walker and
               Thomas Zimmermann},
  title     = {Recommendation Systems in Software Engineering},
  booktitle = {Recommendation Systems in Software Engineering},
  publisher = {Springer},
  year      = {2014},
  url       = {http://dx.doi.org/10.1007/978-3-642-45135-5},
  doi       = {10.1007/978-3-642-45135-5},
  isbn      = {978-3-642-45134-8},
  timestamp = {Mon, 08 Sep 2014 14:46:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/books/sp/rsse2014},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}



@article{me11f,
  title =	 "Learning Better Inspection Optimization Policies",
  author =	 "M. Lumpe and R. Vasa and T. Menzies and R. Rush and
                  R. Turhan",
  class =	 "hJ",
  volume =	 21,
  number =	 45,
  pages =	 "725-753",
  year =	 2011,
  class =	 "hJ",
  journal =	 "International Journal of Software Engineering and
                  Knowledge Engineering"
}



@inproceedings{zhang14,
 author = {Zhang, Feng and Mockus, Audris and Keivanloo, Iman and Zou, Ying},
 title = {Towards Building a Universal Defect Prediction Model},
 booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
 series = {MSR 2014},
 year = {2014},
 isbn = {978-1-4503-2863-0},
 location = {Hyderabad, India},
 pages = {182--191},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2597073.2597078},
 doi = {10.1145/2597073.2597078},
 acmid = {2597078},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Universal defect prediction model, bug, context factors, defect, defect prediction, large scale, quality, rank transformation},
} 




@ARTICLE{Mendes2007,
  author =	 {Kitchenham, Barbara and Mendes, Emilia and
                  Travassos, Guilherme H.},
  title =	 {Cross versus Within-Company Cost Estimation Studies:
                  A Systematic Review},
  journal =	 {IEEE Trans. Softw. Eng.},
  year =	 2007,
  volume =	 33,
  pages =	 {316--329},
  number =	 5,
  note =	 {Member-Kitchenham, Barbara A.},
  address =	 {Piscataway, NJ, USA},
  doi =		 {http://dx.doi.org/10.1109/TSE.2007.1001},
  issn =	 {0098-5589},
  publisher =	 {IEEE Press}
}


@inproceedings{zimmermann09,
  author =	 "T. Zimmermann and N.  Nagappan and H.  Gall and E.
                  Giger and B.  Murphy",
  title =	 "Cross-Project Defect Prediction",
  booktitle =	 "ESEC/FSE'09",
  month =	 "August",
  year =	 2009
}


@inproceedings{peters15,
  title="LACE2: Better Privacy-Preserving 
         Data Sharing for Cross Project Defect Prediction",
  author="Fayola Peters, Tim Menzies, Lucas Layman",
  booktitle="ICSE'15",
  year=2015
}

@inproceedings{nam13,
 author = {Nam, Jaechang and Pan, Sinno Jialin and Kim, Sunghun},
 title = {Transfer Defect Learning},
 booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
 series = {ICSE '13},
 year = {2013},
 isbn = {978-1-4673-3076-3},
 location = {San Francisco, CA, USA},
 pages = {382--391},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=2486788.2486839},
 acmid = {2486839},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
} 


@inproceedings{he13,
  author    = {Zhimin He and
               Fayola Peters and
               Tim Menzies and
               Ye Yang},
  title     = {Learning from Open-Source Projects: An Empirical Study on Defect Prediction},
  booktitle = {2013 {ACM} / {IEEE} International Symposium on Empirical Software
               Engineering and Measurement, Baltimore, Maryland, USA, October 10-11,
               2013},
  pages     = {45--54},
  year      = {2013},
  crossref  = {DBLP:conf/esem/2013},
  url       = {http://dx.doi.org/10.1109/ESEM.2013.20},
  doi       = {10.1109/ESEM.2013.20},
  timestamp = {Mon, 04 Aug 2014 17:08:35 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/esem/HePMY13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{Nam15,
 author = {Nam, Jaechang and Kim, Sunghun},
 title = {Heterogeneous Defect Prediction},
 booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
 series = {ESEC/FSE 2015},
 year = {2015},
 isbn = {978-1-4503-3675-8},
 location = {Bergamo, Italy},
 pages = {508--519},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2786805.2786814},
 doi = {10.1145/2786805.2786814},
 acmid = {2786814},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Defect prediction, heterogeneous metrics, quality assurance},
} 


@inproceedings{Jing15,
 author = {Jing, Xiaoyuan and Wu, Fei and Dong, Xiwei and Qi, Fumin and Xu, Baowen},
 title = {Heterogeneous Cross-company Defect Prediction by Unified Metric Representation and CCA-based Transfer Learning},
 booktitle = {Proc. of the 10th Joint Meeting on Foundations of Software Engineering},
 year = {2015},
 isbn = {978-1-4503-3675-8},
 location = {Bergamo, Italy},
 pages = {496--507},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2786805.2786813},
 doi = {10.1145/2786805.2786813},
 acmid = {2786813},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Heterogeneous cross-company defect prediction (HCCDP), canonical correlation analysis (CCA), common metrics, company-specific metrics, unified metric representation},
} 



@inproceedings{olbrich2010all,
  title={Are all code smells harmful? A study of God Classes and Brain Classes in the evolution of three open source systems},
  author={Olbrich, Steffen M and Cruzes, Daniela S and Sj{\o}berg, Dag IK},
  booktitle={Software Maintenance (ICSM), 2010 IEEE International Conference on},
  pages={1--10},
  year={2010}
}
@inproceedings{zazworka2011investigating,
  title={Investigating the impact of design debt on software quality},
  author={Zazworka, Nico and Shaw, Michele A and Shull, Forrest and Seaman, Carolyn},
  booktitle={Proceedings of the 2nd Workshop on Managing Technical Debt},
  pages={17--23},
  year={2011},
  organization={ACM}
}

@inproceedings{Olbrich2009,
 author = {Olbrich, Steffen and Cruzes, Daniela S. and Basili, Victor and Zazworka, Nico},
 title = {The Evolution and Impact of Code Smells: A Case Study of Two Open Source Systems},
 booktitle = {Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement},
 series = {ESEM '09},
 year = {2009},
 isbn = {978-1-4244-4842-5},
 pages = {390--400},
 numpages = {11},
 url = {http://dx.doi.org/10.1109/ESEM.2009.5314231},
 doi = {10.1109/ESEM.2009.5314231},
 acmid = {1671285},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 

@INPROCEEDINGS{Mantyla2004, 
author={Mantyla, M.V. and Vanhanen, J. and Lassenius, C.}, 
booktitle={Software Maintenance, 2004. Proceedings. 20th IEEE International Conference on}, 
title={Bad smells - humans as code critics}, 
year={2004}, 
month={Sept}, 
pages={399-408}, 
keywords={program diagnostics;software houses;software metrics;software performance evaluation;Finnish software product company;bad code smell;code evaluation;code modules;poor software structures;source code metrics;subjective evaluation;Companies;Current measurement;Internet;Programming;Quality assessment;Software design;Software maintenance;Software measurement;Software quality;Software tools}, 
doi={10.1109/ICSM.2004.1357825}, 
ISSN={1063-6773},}



@inproceedings{platt05,
	Author = {John C. Platt},
	Booktitle = {In Proceedings of 10th International Workshop on Artificial Intelligence and Statistics},
	Pages = {261--268},
	Title = {{FastMap}, {MetricMap}, and {L}andmark {MDS} are all {Nystr{\"o}m} algorithms},
	Year = 2005}
	
	
@article{Pedregosa2012,
abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
archivePrefix = {arXiv},
arxivId = {1201.0490},
author = {Pedregosa, Fabian and Varoquaux, Ga\"{e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, \'{E}douard},
eprint = {1201.0490},
file = {::},
isbn = {1532-4435},
issn = {15324435},
journal = { Journal Machine Learning },
pages = {2825--2830},
title = {{Scikit-learn: Machine Learning in Python}},
url = {http://dl.acm.org/citation.cfm?id=2078195$\backslash$nhttp://arxiv.org/abs/1201.0490},
volume = {12},
year = {2012}
}


@article{Anda2009,
abstract = {The scientific study of a phenomenon requires it to be reproducible. Mature engineering industries are recognized by projects and products that are, to some extent, reproducible. Yet, reproducibility in software engineering (SE) has not been investigated thoroughly, despite the fact that lack of reproducibility has both practical and scientific consequences. We report a longitudinal multiple-case study of variations and reproducibility in software development, from bidding to deployment, on the basis of the same requirement specification. In a call for tender to 81 companies, 35 responded. Four of them developed the system independently. The firm price, planned schedule, and planned development process, had, respectively, ldquolow,rdquo ldquolow,rdquo and ldquomediumrdquo reproducibilities. The contractor's costs, actual lead time, and schedule overrun of the projects had, respectively, ldquomedium,rdquo ldquohigh,rdquo and ldquolowrdquo reproducibilities. The quality dimensions of the delivered products, reliability, usability, and maintainability had, respectively, ldquolow,rdquo "high,rdquo and ldquolowrdquo reproducibilities. Moreover, variability for predictable reasons is also included in the notion of reproducibility. We found that the observed outcome of the four development projects matched our expectations, which were formulated partially on the basis of SE folklore. Nevertheless, achieving more reproducibility in SE remains a great challenge for SE research, education, and industry.},
author = {Anda, Bente C D and Sj\o berg, Dag I K and Mockus, Audris},
doi = {10.1109/TSE.2008.89},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Multiple-case study,Software engineering life cycle,Software process,Software project success,Software quality},
number = {3},
pages = {407--429},
title = {{Variability and reproducibility in software engineering: A study of four companies that developed the same system}},
volume = {35},
year = {2009}
}


@article{Mkaouer15,
author = {{Wiem Mkaouer, Marouane Kessentini,; Slim Bechikh, Kalyanmoy Deb}, Ali Ouni and \'{U}\^{u}, \'{O}},
journal = {ACM Trans. Softw. Eng. Methodol.},
title = {{Many-Objective Software Remodularization using NSGA-III}},
volume = {to appear},
year = {2015}
}

@inproceedings{Binkley2006,
abstract = {Aspect-oriented programming (AOP) provides mechanisms for the separation of crosscutting concerns - functionalities scattered through the system and tangled with the base code. Existing systems are a natural testbed for the AOP approach since they often contain several crosscutting concerns which could not be modularized using traditional programming constructs. This paper presents an automated approach to the problem of migrating systems developed according to the object-oriented programming (OOP) paradigm into aspect-oriented programming (AOP). A simple set of six refactorings has been defined to transform OOP to AOP and has been implemented in the AOP-migrator tool, an Eclipse plug-in. A set of enabling transformations from OOP to OOP complement the initial set of refactorings. The paper presents the results of four case studies, which use the approach to migrate selected crosscutting concerns from medium-sized Java programs (in the range of 10K to 40K lines of code) into equivalent programs in AspectJ. The case study results show the feasibility of the migration and indicate the importance of the enabling transformations as a preprocessing step},
author = {Binkley, David and Ceccato, Mariano and Harman, Mark and Ricca, Filippo and Tonella, Paolo},
booktitle = {IEEE Transactions on Software Engineering},
doi = {10.1109/TSE.2006.95},
issn = {00985589},
keywords = {Aspect-oriented software development,Program transformation,Refactoring},
number = {9},
pages = {698--717},
title = {{Tool-supported refactoring of existing object-oriented code into aspects}},
volume = {32},
year = {2006}
}


@inproceedings{fea02a,
author = {Feather, M S and Menzies, T},
booktitle = {IEEE Joint Conference On Requirements Engineering ICRE'02 and RE'02, 9-13th September, University of Essen, Germany},
title = {{Converging on the Optimal Attainment of Requirements}},
year = {2002}
}


@ARTICLE{menzies13:brady, 
author={Menzies, T. and Brady, A. and Keung, J. and Hihn, J. and Williams, S. and El-Rawas, O. and Green, P. and Boehm, B.}, 
journal={Software Engineering, IEEE Transactions on}, 
title={Learning Project Management Decisions: A Case Study with Case-Based Reasoning versus Data Farming}, 
year={2013}, 
month={Dec}, 
volume={39}, 
number={12}, 
pages={1698-1713}, 
keywords={Monte Carlo methods;case-based reasoning;data handling;learning (artificial intelligence);project management;sampling methods;software management;CBR;Monte Carlo sampling;SEESAW;case-based reasoning;data farming;project management decision learning;software project data;Data models;Mathematical model;Monte Carlo methods;Project management;Search methods;Software engineering;COCOMO;Search-based software engineering;case-based reasoning;data farming}, 
doi={10.1109/TSE.2013.43}, 
ISSN={0098-5589},}


@inproceedings{me07f,
abstract = {Adoption of advanced automated SE (ASE) tools would be favored if a business case could be made that these tools are more valuable than alternate methods. In theory, software prediction models can be used to make that case. In practice, this is complicated by the "local tuning" problem. Normally, predictors for software effort and defects and threat use local data to tune their predictions. Such local tuning data is often unavailable. This paper shows that assessing the relative merits of different SE methods need not require precise local tunings. STAR1 is a simulated annealer plus a Bayesian post-processor that explores the space of possible local tunings within software prediction models. STAR1 ranks project decisions by their effects on effort and defects and threats. In experiments with two NASA systems, STAR1 found that ASE tools were necessary to minimize effort/ defect/ threats.},
address = {New York, NY, USA},
author = {Menzies, Tim and Feather, Martin S and Madachy, Ray and Boehm, Barry W.},
booktitle = {Proc. ASE},
doi = {http://doi.acm.org/10.1145/1321631.1321676},
isbn = {978-1-59593-882-4},
pages = {303--312},
publisher = {ACM},
title = {{The Business Case for Automated Software Engineering}},
url = {http://portal.acm.org/citation.cfm?id=1321631.1321676},
year = {2007}
}



@incollection{peng09:ls,
year={2009},
isbn={978-3-540-88050-9},
booktitle={Multi-Objective Memetic Algorithms},
volume={171},
series={Studies in Computational Intelligence},
editor={Goh, Chi-Keong and Ong, Yew-Soon and Tan, KayChen}, 
title={Comparison between MOEA/D and NSGA-II on the Multi-Objective Travelling Salesman Problem},
url={http://dx.doi.org/10.1007/978-3-540-88051-6_14},
publisher={Springer Berlin Heidelberg},
author={Peng, Wei and Zhang, Qingfu and Li, Hui},
pages={309-324},
language={English}
}


@article{igel07,
 author = {Igel, Christian and Hansen, Nikolaus and Roth, Stefan},
 title = {Covariance Matrix Adaptation for Multi-objective Optimization},
 journal = {Evol. Comput.},
 issue_date = {Spring 2007},
 volume = {15},
 number = {1},
 month = mar,
 year = {2007},
 issn = {1063-6560},
 pages = {1--28},
 numpages = {28}, 
 acmid = {1245373},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
 keywords = {Multi-objective optimization, covariance matrix adaptation, evolution strategy},
} 


@inproceedings{kautz97,
  author =	 "H. Kautz and B. Selman and Y. Jiang",
  year =	 1997,
  title =	 "A general stochastic approach to solving problems
                  with hard and soft constraints",
  editor =	 "D. Gu and J. Du and P. Pardalos",
  booktitle =	 "The Satisfiability Problem: Theory and Applications,
                  New York, NY",
  pages =	 " 573--586",
  note =	 "Available on-line at
                  \url{http://citeseer.ist.psu.edu/168907.html}"
}


@online{Atwood06,
 author = {Jeff Atwood},
 title = {Code Smells},
 year = 2006,
 url = {http://blog.codinghorror.com/code-smells/},
 urldate={2015-07-06}
}

@article{Selman1992,
abstract = {We introduce a greedy local search procedure called GSAT for solving propositional satisfiability problems. Our experiments show that this procedure can be used to solve hard, randomly generated problems that are an order of magnitude larger than those that can be handled by more traditional approaches such as the Davis-Putnam procedure or resolution. We also show that GSAT can solve structured satisfiability problems quickly. In particular, we solve encodings of graph coloring problems, N-queens, and Boolean induction. General application strategies and limitations of the approach are also discussed. GSAT is best viewed as a model-finding procedure. Its good performance suggests that it may be advantageous to reformulate reasoning tasks that have traditionally been viewed as theorem-proving problems as model-finding tasks.},
author = {Selman, Bart and Levesque, Hector and Mitchell, David},
isbn = {0-262-51063-4},
issn = {08828121},
journal = {Proceedings of the Tenth National Conference on Artificial Intelligence (AAAI'92)},
pages = {440--446},
title = {{A New Method for Solving Hard Satisfiability Problems}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.6853\&amp;rep=rep1\&amp;type=pdf},
volume = {20},
year = {1992}
}


@inproceedings{levina04,
author = {Levina, Elizaveta and Bickel, Peter J},
booktitle = {NIPS},
file = {:Users/timm/svns/doc/04intrinsicDimension.pdf:pdf},
title = {{Maximum Likelihood Estimation of Intrinsic Dimension.}},
year = {2004}
}
@article{deb00a,
author = {Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, T},
journal = {IEEE Transactions on Evolutionary Computation},
pages = {182--197},
title = {{A Fast Elitist Multi-Objective Genetic Algorithm: NSGA-II}},
volume = {6},
year = {2002}
}

@article{Khuller1995,
abstract = {We present a linear time randomized sieve algorithm for the closest-pair problem. The algorithm and its analysis are simple. The algorithm is extended to obtain a randomized linear time approximation algorithm for the closest bichromatic pair problem.},
author = {Khuller, S and Matias, Y},
doi = {10.1006/inco.1995.1049},
issn = {08905401},
journal = {Information and Computation},
number = {1},
pages = {34--37},
title = {{A Simple Randomized Sieve Algorithm for the Closest-Pair Problem}},
url = {http://www.sciencedirect.com/science/article/pii/S0890540185710498},
volume = {118},
year = {1995}
}


@article{Shamos1975,
abstract = {A number of seemingly unrelated problems involving the proximity of N points in the plane are studied, such as finding a Euclidean minimum spanning tree, the smallest circle enclosing the set, k nearest and farthest neighbors, the two closest points, and a proper straight-line triangulation. For most of the problems considered a lower bound of O(N log N) is shown. For all of them the best currently-known upper bound is O(N2) or worse. The purpose of this paper is to introduce a single geometric structure, called the Voronoi diagram, which can be constructed rapidly and contains all of the relevant proximity information in only linear space. The Voronoi diagram is used to obtain O(N log N) algorithms for all of the problems.},
author = {Shamos, Michael Ian and Hoey, Dan},
doi = {10.1109/SFCS.1975.8},
isbn = {0272-5428},
issn = {0272-5428},
journal = {16th Annual Symposium on Foundations of Computer Science (sfcs 1975)},
title = {{Closest-point problems}},
year = {1975}
}


@inproceedings{me09j,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09pom2.pdf\}},
author = {Lemon, B and Riesbeck, A and Menzies, T and Price, J and D'Alessandro, J and Carlsson, R and Prifiti, T and Peters, F and Lu, H and Port, D},
booktitle = {IEEE ASE'09},
title = {{Applications of Simulation and AI Search: Assessing the Relative Merits of Agile vs Traditional Software Development}},
year = {2009}
}

@article{Chawla2002,
abstract = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of "normal" examples with only a small percentage of "abnormal" or "interesting" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.},
archivePrefix = {arXiv},
arxivId = {1106.1813},
author = {Chawla, Nitesh V. and Bowyer, Kevin W. and Hall, Lawrence O. and Kegelmeyer, W. Philip},
doi = {10.1613/jair.953},
eprint = {1106.1813},
isbn = {013805326X},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
pages = {321--357},
pmid = {18190633},
title = {{SMOTE: Synthetic minority over-sampling technique}},
volume = {16},
year = {2002}
}


@article{Cui2005a,
author = {Cui, X and Potok, Te and Palathingal, P},
file = {:Users/timm/svns/doc/pso/05clusterPSO.pdf:pdf},
journal = {\ldots  Intelligence Symposium, 2005. \ldots},
title = {{Document clustering using particle swarm optimization}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1501621},
year = {2005}
}


@inproceedings{me09i,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09value.pdf\}},
author = {Green, P and Menzies, T and Williams, S and El-waras, O},
booktitle = {IEEE ASE'09},
title = {{Understanding the Value of Software Engineering Technologies}},
year = {2009}
}

@article{storn97,
author = {Storn, Rainer and Price, Kenneth},
doi = {10.1023/A:1008202821328},
file = {:Users/timm/svns/doc/97stornPriceDE.pdf:pdf},
issn = {0925-5001},
journal = {Journal of Global Optimization},
number = {4},
pages = {341--359},
publisher = {Kluwer Academic Publishers},
title = {{Differential Evolution --- A Simple and Efficient Heuristic for global Optimization over Continuous Spaces}},
volume = {11},
year = {1997}
}




@incollection{zit04,
author = {Zitzler, Eckart and K\"{u}nzli, Simon},
booktitle = {Parallel Problem Solving from Nature - PPSN VIII},
doi = {10.1007/978-3-540-30217-9\_84},
editor = {Yao, Xin and Burke, EdmundK. and Lozano, Jos\'{e}A. and Smith, Jim and Merelo-Guerv\'{o}s, JuanJuli\'{a}n and Bullinaria, JohnA. and Rowe, JonathanE. and Tiňo, Peter and Kab\'{a}n, Ata and Schwefel, Hans-Paul},
file = {:Users/timm/svns/doc/04zitzlerIBEA.pdf:pdf},
isbn = {978-3-540-23092-2},
pages = {832--842},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Indicator-Based Selection in Multiobjective Search}},
url = {http://dx.doi.org/10.1007/978-3-540-30217-9\_84},
volume = {3242},
year = {2004}
}

@inproceedings{Cheng10,
 author = {Cheng, Betty and Jensen, Adam   },
 title = {On the Use of Genetic Programming for Automated Refactoring and the Introduction of Design Patterns},
 booktitle = {Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation},
 series = {GECCO '10},
 year = {2010},
 isbn = {978-1-4503-0072-8},
 location = {Portland, Oregon, USA},
 pages = {1341--1348},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1830483.1830731},
 doi = {10.1145/1830483.1830731},
 acmid = {1830731},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {design patterns, evolutionary computation, intelligent search, object-oriented design, refactoring, search-based software engineering, software metrics},
} 
[download]

@article{OKeeffe08,
 author = {O'Keeffe, Mark and Cinn{\'e}ide, Mel \'{O}},
 title = {Search-based Refactoring: An Empirical Study},
 journal = {J. Softw. Maint. Evol.},
 issue_date = {September 2008},
 volume = {20},
 number = {5},
 month = sep,
 year = {2008},
 issn = {1532-060X},
 pages = {345--364},
 numpages = {20},
 url = {http://dx.doi.org/10.1002/smr.v20:5},
 doi = {10.1002/smr.v20:5},
 acmid = {1416585},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA},
 keywords = {automated design improvement, refactoring tools, search-based software engineering},
} 



@inproceedings{OKeeffe07,
 author = {O'Keeffe, Mark Kent and Cinneide, Mel O.},
 title = {Getting the Most from Search-based Refactoring},
 booktitle = {Proceedings of the 9th Annual Conference on Genetic and Evolutionary Computation},
 series = {GECCO '07},
 year = {2007},
 isbn = {978-1-59593-697-4},
 location = {London, England},
 pages = {1114--1120},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/1276958.1277177},
 doi = {10.1145/1276958.1277177},
 acmid = {1277177},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {automated design improvement, object-oriented product metrics, refactoring, search-based software engineering},
} 


@article{Bansiya02,
 author = {Bansiya, Jagdish and Davis, Carl G.},
 title = {A Hierarchical Model for Object-Oriented Design Quality Assessment},
 journal = {IEEE Trans. Softw. Eng.},
 issue_date = {January 2002},
 volume = {28},
 number = {1},
 month = jan,
 year = {2002},
 issn = {0098-5589},
 pages = {4--17},
 numpages = {14},
 url = {http://dx.doi.org/10.1109/32.979986},
 doi = {10.1109/32.979986},
 acmid = {513066},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {quality model, quality attributes, design metrics, product metrics, object-oriented metrics},
} 
[download]

@inproceedings{Harman07,
 author = {Harman, Mark and Tratt, Laurence},
 title = {Pareto Optimal Search Based Refactoring at the Design Level},
 booktitle = {Proceedings of the 9th Annual Conference on Genetic and Evolutionary Computation},
 series = {GECCO '07},
 year = {2007},
 isbn = {978-1-59593-697-4},
 location = {London, England},
 pages = {1106--1113},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1276958.1277176},
 doi = {10.1145/1276958.1277176},
 acmid = {1277176},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Pareto optimality, refactoring, search based, software engineering},
}  

@inproceedings{Seng06,
 author = {Seng, Olaf and Stammel, Johannes and Burkhart, David},
 title = {Search-based Determination of Refactorings for Improving the Class Structure of Object-oriented Systems},
 booktitle = {Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation},
 series = {GECCO '06},
 year = {2006},
 isbn = {1-59593-186-4},
 location = {Seattle, Washington, USA},
 pages = {1909--1916},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1143997.1144315},
 doi = {10.1145/1143997.1144315},
 acmid = {1144315},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {design heuristics, evolutionary algorithms, refactoring, software metrics},
} 


@inproceedings{zit02,
author = {Zitzler, Eckart and Laumanns, Marco and Thiele, Lothar},
booktitle = {Evolutionary Methods for Design, Optimisation, and Control},
pages = {95--100},
publisher = {CIMNE, Barcelona, Spain},
title = {{SPEA2: Improving the Strength Pareto Evolutionary Algorithm for Multiobjective Optimization}},
year = {2002}
}

@article{boley98,
author = {Boley, Daniel},
file = {:Users/timm/svns/doc/98principalDirectionDivisvePartitioning.pdf:pdf},
journal = {Data Min. Knowl. Discov.},
month = dec,
number = {4},
pages = {325--344},
title = {{Principal Direction Divisive Partitioning}},
volume = {2},
year = {1998}
}

@book{cohen95,
author = {Cohen, P R},
publisher = {MIT Press},
title = {{Empirical Methods for Artificial Intelligence}},
year = {1995}
}


@inproceedings{FayIra93Multi,
author = {Fayyad, U M and Irani, I H},
booktitle = {Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence},
pages = {1022--1027},
title = {{Multi-interval Discretization of Continuous-valued Attributes for Classification Learning}},
year = {1993}
}


@article{hall03,
author = {Hall, M A and Holmes, G},
file = {:Users/timm/svns/doc/03hall.pdf:pdf},
journal = {IEEE Transactions On Knowledge And Data Engineering},
number = {6},
pages = {1437--1447},
title = {{Benchmarking Attribute Selection Techniques for Discrete Class Data Mining}},
volume = {15},
year = {2003}
}


@article{kohavi97,
author = {Kohavi, Ron and John, George H},
journal = {Artificial Intelligence},
number = {1-2},
pages = {273--324},
title = {{Wrappers for Feature Subset Selection}},
url = {citeseer.nj.nec.com/kohavi96wrappers.html},
volume = {97},
year = {1997}
}


@mastersthesis{divya15,
  author= "Divya Ganesan",
  title=  "Exploring Essential content of Defect Prediction 
           and Effort Estimation
           through Data Reduction",
  school= "Lane Department of Computer Science and 
           Electrical Engineering, West Virginia University",
  year=    2015
}

@mastersthesis{papa13,
  author="Vasil Papakroni",
  title="Data Carving: Identifying and Removing Irrelevancies in the Data",
  school="Lane Department of Computer Science and Electrical Engineering, West Virginia Unviersity",
  year=2013
}
@article{deb14,
author = {Deb, K and Jain, H},
doi = {10.1109/TEVC.2013.2281535},
file = {:Users/timm/svns/doc/13nsga-III.pdf:pdf},
issn = {1089-778X},
journal = {Evolutionary Computation, IEEE Transactions on},
keywords = {genetic algorithms;sorting;EMO algorithms;MOEA/D m},
month = aug,
number = {4},
pages = {577--601},
title = {{An Evolutionary Many-Objective Optimization Algorithm Using Reference-Point-Based Nondominated Sorting Approach, Part I: Solving Problems With Box Constraints}},
volume = {18},
year = {2014}
}

@article{zhang07:TEC,
author = {Zhang, Qingfu and Li, Hui},
doi = {10.1109/TEVC.2007.892759},
issn = {1089-778X},
journal = {Evolutionary Computation, IEEE Transactions on},
keywords = {computational complexity;genetic algorithms;comput},
month = dec,
number = {6},
pages = {712--731},
title = {{MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition}},
volume = {11},
year = {2007}
}



@inproceedings{me02f,
author = {Menzies, Tim and Raffo, David and Setamanit, Siri-on and Hu, Ying and Tootoonian, Sina},
booktitle = {Proceedings of IEEE ASE 2002},
title = {{Model-based Tests of Truisms}},
year = {2002}
}

@inproceedings{me00e,
author = {Menzies, T and Sinsel, E},
booktitle = {Proceedings ASE 2000},
title = {{Practical Large Scale What-if Queries: Case Studies with Software Risk Assessment}},
year = {2000}
}


@misc{Fikes1971,
abstract = {We describe a new problem solver called STRIPS that attempts to find a sequence of operators in a space of world models to transform a given initial world model in which a given goal formula can be proven to be true. STRIPS represents a world model as an arbitrary collection in first-order predicate calculus formulas and is designed to work with models consisting of large numbers of formula. It employs a resolution theorem prover to answer questions of particular models and uses means-ends analysis to guide it to the desired goal-satisfying model.},
author = {Fikes, Richard E. and Nilsson, Nils J.},
booktitle = {Artificial Intelligence},
doi = {10.1016/0004-3702(71)90010-5},
isbn = {0004-3702},
issn = {00043702},
number = {3-4},
pages = {189--208},
title = {{Strips: A new approach to the application of theorem proving to problem solving}},
volume = {2},
year = {1971}
}


@inproceedings{zuluaga13,
author = {Zuluaga, Marcela and Krause, Andreas and Sergent, Guillaume and P\"{u}schel, Markus},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Active Learning for Multi-Objective Optimization}},
year = {2013}
}

@article{pearson1901,
author = {Pearson, K},
journal = {Philosophical Magazine},
pages = {559--572},
title = {{On lines and planes of closest fit to systems of points in space}},
volume = {2},
year = {1901}
}



@inproceedings{kamvar03,
author = {Kamvar, Sepandar and Klein, Dan and Manning, Christopher},
booktitle = {IJCAI'03},
pages = {561--566},
title = {{Spectral learning}},
year = {2003}
}

@proceedings{DBLP:conf/esem/2013,
  title     = {2013 {ACM} / {IEEE} International Symposium on Empirical Software
               Engineering and Measurement, Baltimore, Maryland, USA, October 10-11,
               2013},
  publisher = {{IEEE} Computer Society},
  year      = {2013},
  url       = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6681322},
  isbn      = {978-0-7695-5056-5},
  timestamp = {Mon, 04 Aug 2014 17:08:35 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/esem/2013},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@book{boehm00b,
author = {Boehm, Barry and Horowitz, Ellis and Madachy, Ray and Reifer, Donald and Clark, Bradford K and Steece, Bert and Brown, A Winsor and Chulani, Sunita and Abts, Chris},
publisher = {Prentice Hall},
title = {{Software Cost Estimation with Cocomo II}},
year = {2000}
}

@book{boehm81,
author = {Boehm, B},
publisher = {Prentice Hall},
title = {{Software Engineering Economics}},
year = {1981}
}

 
 
 @inproceedings{madachy94,
author = {Madachy, R},
booktitle = {Proceedings Ninth Knowledge-Based Software Engineering Conference},
pages = {172--178},
title = {{Knowledge-based risk assessment and cost estimation}},
year = {1994}
}

 
 @inproceedings{me00e,
abstract = {When a lack of data inhibits decision-making, large-scale what-if
queries can be conducted over the uncertain parameter ranges. Such
queries can generate an overwhelming amount of data. We describe a
general method for understanding that data. Large-scale what-if queries
can guide Monte Carlo simulations of a model. Machine learning can then
be used to summarize the output. The summarization is an ensemble of
decision trees. The TARZAN system [so-called because it swings through
(or searches) the decision trees] can poll the ensemble looking for
majority conclusions regarding what factors change the classifications
of the data. TARZAN can succinctly present the results from very large
what-if queries. For example, in one of the studies presented, we can
view the significant features from 10<sup>9</sup> what-if queries on
half a page},
author = {Menzies, T. and Sinsel, E.},
booktitle = {Proceedings ASE 2000. Fifteenth IEEE International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2000.873661},
isbn = {0-7695-0710-7},
issn = {1527-1366},
title = {{Practical large scale what-if queries: case studies with software
risk assessment}},
year = {2000}
}


@article{me09b,
  title =	 "On the Relative Value of Cross-Company and
                  Within-Company Data for Defect Prediction",
  author =	 "B. Turhan and Tim Menzies and A. Bener and
                  J. Distefano",
  year =	 2009,
  journal =	 "Empirical Software Engineering",
  volume =	 68,
  number =	 2,
  pages =	 "278-290",
  note =	 "Available from
                  \url{http://menzies.us/pdf/08ccwc.pdf}",
  class =	 "hJ"
}

@misc{Zadeh1965,
abstract = {A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint.},
author = {Zadeh, L.A.},
booktitle = {Information and Control},
doi = {10.1016/S0019-9958(65)90241-X},
isbn = {0019-9958},
issn = {00199958},
number = {3},
pages = {338--353},
title = {{Fuzzy sets}},
volume = {8},
year = {1965}
}


@article{me07b,
  author =	"T. Menzies and J. Greenwald and A. Frank",
  year =	2007,
  month =	"Jan",
  volume={33}, 
  number={1}, 
  pages={2-13}, 
  title =	"Data Mining Static Code Attributes to Learn Defect
                  Predictors",
  journal =	"IEEE Trans. Softw Eng.",
  note =	"Available from
                  \url{http://menzies.us/pdf/06learnPredict.pdf}",
  class =	"hJ", 
}


@article{me11f,
author = {Lumpe, M and Vasa, R and Menzies, T and Rush, R and Turhan, R},
journal = {International Journal of Software Engineering and Knowledge Engineering},
number = {45},
pages = {725--753},
title = {{Learning Better Inspection Optimization Policies}},
volume = {21},
year = {2011}
}


@article{jiang2013incremental,
  title={Incremental Development of Fault Prediction Models},
  author={Jiang, Yue and Cukic, Bojan and Menzies, Tim and Lin, Jie},
  journal={International Journal of Software Engineering and Knowledge Engineering},
  volume={23},
  number={10},
  pages={1399--1425},
  year={2013},
  publisher={World Scientific Publishing Company}
}


@book{fastmap,
  title={FastMap: A fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets},
  author={Faloutsos, Christos and Lin, King-Ip},
  volume={24},
  number={2},
  year={1995},
  publisher={ACM}
}
@inproceedings{xomo,
  title={Xomo: Understanding development options for autonomy},
  author={Menzies, Tim}
}

@inproceedings{Carver2003,
abstract = {Several empirical studies have been carried out with college students as subjects in the last few years. Researchers often use these studies to pilot experiments before they are carried out in industrial environments. Reports on these studies usually focus on the results obtained and issues such as their external validity. However, the effects and value of empirical studies with students may go beyond the contribution to scientific literature. For instance, the pedagogical challenges and value of these studies is hardly ever stressed. We identify four primary actors that are involved in these empirical studies, i.e., researchers, students, instructors, and industry. We discuss the costs and benefits of empirical studies with students for these actors, which are different because of the actors' different goals, expectations, and constraints, which must be recognized to fully exploit empirical studies with students. We also provide some advice on how to carry out empirical studies with students based on our experiences.},
author = {Carver, Jeffrey and Jaccheri, Letizia and Morasca, Sandro and Shull, Forrest},
booktitle = {Proceedings of the 9th International Software Metrics Symposium (METRICS '03)},
doi = {10.1109/METRIC.2003.1232471},
isbn = {0-7695-1987-3},
pages = {239--249},
title = {{Issues in using students in empirical studies in software engineering education}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1232471},
year = {2003}
}

@book{Schank1977,
abstract = {Related to my topic. However, it's not really clear how it all works together. Moore BF 311 S378},
author = {Schank, Roger C and Abelson, Robert P},
booktitle = {Representation},
file = {::},
isbn = {9780470990339},
pages = {272},
pmid = {91},
title = {{Scripts, Plans, Goals and Understanding}},
url = {http://books.google.it/books?id=YZ99AAAAMAAJ},
volume = {Discourse},
year = {1977}
}


@article{Kolodner1992,
abstract = {Case-based reasoning means using old experiences to understand and solve new problems. In case-based reasoning, a reasoner remembers a previous situation similar to the current one and uses that to solve the new problem. Case- based reasoning can mean adapting old solutions to meet new demands; using old cases to explain new situations; using old cases to critique new solutions; or reasoning from precedents to interpret a new situation (much like lawyers do) or create an equitable solution to a new problem (much like labor mediators do). This paper discusses the processes involved in case-based reasoning and the tasks for which case-based reasoning is useful.},
author = {Kolodner, Janet L.},
doi = {10.1007/BF00155578},
isbn = {978-3-540-60654-3},
issn = {02692821},
journal = {Artificial Intelligence Review},
keywords = {Case-based reasoning,experience,problem-solving},
number = {1},
pages = {3--34},
title = {{An introduction to case-based reasoning}},
volume = {6},
year = {1992}
}

@article{dean1995planning,
  title={Planning under time constraints in stochastic domains},
  author={Dean, Thomas and Kaelbling, Leslie Pack and Kirman, Jak and Nicholson, Ann},
  journal={Artificial Intelligence},
  volume={76},
  number={1-2},
  pages={35--74},
  year={1995},
  publisher={Elsevier}
}
@misc{Bylander1994,
abstract = {I present several computationalcomplexity results for propositionalSTRIPSplanning, i.e., STRIPSplanning restricted to ground formulas. Different planning problems can be defined by restricting the type of formulas, placing limits on the number of pre-and postconditions, by restricting negation in pre- and postconditions, and by requiring optimal plans. For these types of restrictions, I show when planning is tractable (polynomial) and intractable (NP-hard). In general, it is PSPACE-complete to determine if a given planning instance has any solutions. Extremely severe restrictions on both the operators and the formulas are required to guarantee polynomial time or even NP-completeness. For example, when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. When definite Horn ground formulas are permitted, determining plan existence is PSPACE-complete even if operators are limited to zero preconditions and one postcondition. One of the interesting tractable problems is if each operator is restricted to positive preconditions and one postcondition (only ground literals). The blocks-world problem, slightly modified, is a subproblem of this restricted planning problem. These results in combination with previous analyses are not encouraging for domain-independent planning.},
author = {Bylander, Tom},
booktitle = {Artificial Intelligence},
doi = {10.1016/0004-3702(94)90081-7},
issn = {00043702},
number = {1-2},
pages = {165--204},
title = {{The computational complexity of propositional STRIPS planning}},
volume = {69},
year = {1994}
}


@inproceedings{me09m,
annote = {Available from  http://menzies.us/pdf/09fssga.pdf},
author = {Andrews, Jamie and Menzies, Tim},
booktitle = {PROMISE'09},
title = {{On the Value of Combining Feature Subset Selection with Genetic Algorithms: Faster Learning of Coverage Models}},
year = {2009}
}

@misc{Fikes1971,
abstract = {We describe a new problem solver called STRIPS that attempts to find a sequence of operators in a space of world models to transform a given initial world model in which a given goal formula can be proven to be true. STRIPS represents a world model as an arbitrary collection in first-order predicate calculus formulas and is designed to work with models consisting of large numbers of formula. It employs a resolution theorem prover to answer questions of particular models and uses means-ends analysis to guide it to the desired goal-satisfying model.},
author = {Fikes, Richard E. and Nilsson, Nils J.},
booktitle = {Artificial Intelligence},
doi = {10.1016/0004-3702(71)90010-5},
isbn = {0004-3702},
issn = {00043702},
number = {3-4},
pages = {189--208},
title = {{Strips: A new approach to the application of theorem proving to problem solving}},
volume = {2},
year = {1971}
}

@inproceedings{Johnson09,
 author = {Johnson, Philip and Zhang, Shaoxuan},
 title = {We Need More Coverage, Stat! Classroom Experience with the Software ICU},
 booktitle = {Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement},
 series = {ESEM '09},
 year = {2009},
 isbn = {978-1-4244-4842-5},
 pages = {168--178},
 numpages = {11},
 url = {http://dx.doi.org/10.1109/ESEM.2009.5315989},
 doi = {10.1109/ESEM.2009.5315989},
 acmid = {1671265},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 


@inproceedings{andrews07,
annote = {Available from  http://menzies.us/pdf/07ase-nighthawk.pdf},
author = {Andrews, J H and Li, F C H and Menzies, T},
booktitle = {IEEE ASE'07},
title = {{Nighthawk: A Two-Level Genetic-Random Unit Test Data Generator}},
year = {2007}
}


@inproceedings{Nagappan05,
 author = {Nagappan, Nachiappan and Ball, Thomas},
 title = {Use of Relative Code Churn Measures to Predict System Defect Density},
 booktitle = {Proceedings of the 27th International Conference on Software Engineering},
 series = {ICSE '05},
 year = {2005},
 isbn = {1-58113-963-2},
 location = {St. Louis, MO, USA},
 pages = {284--292},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/1062455.1062514},
 doi = {10.1145/1062455.1062514},
 acmid = {1062514},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {defect density, fault-proneness, multiple regression, principal component analysis, relative code churn},
} 


@article{andrews10,
author = {Andrews, James H and Menzies, Tim and Li, Felix C H},
journal = {IEEE Transactions on Software Engineering},
month = mar,
title = {{Genetic Algorithms for Randomized Unit Testing}},
year = {2010}
}


@article{Hill1965,
author = {Hill, Austin Bradford},
journal = {Proceedings of the Royal Society of Medicine},
number = {5},
pages = {295--300},
title = {{The Environment and Disease: Association or Causation?}},
volume = {58},
year = {1965}
}

@inproceeeings{Seth2007,
abstract = {Granger causality is a statistical concept of causality that is based on prediction. According to Granger causality, if a signal X1 "Granger-causes" (or "G-causes") a signal X2, then past values of X1 should contain information that helps predict X2 above and beyond the information contained in past values of X2 alone. Its mathematical formulation is based on linear regression modeling of stochastic processes (Granger 1969). More complex extensions to nonlinear cases exist, however these extensions are often more difficult to apply in practice.},
author = {Seth, Anil},
booktitle = {Scholarpedia},
doi = {10.4249/scholarpedia.1667},
issn = {1941-6016},
number = {7},
pages = {1667},
pmid = {20812909},
title = {{Granger causality}},
volume = {2},
year = {2007}
}

@article{granger80,
abstract = {A general definition of causality is introduced and then specialized to become operational. By considering simple examples a number of advantages and also difficulties are discussed.},
author = {{C. W. J. Granger}},
doi = {10.1016/0165-1889(80)90069-X},
isbn = {0165-1889},
issn = {01651889},
journal = {Journal of Economic Dynamics and Control},
pages = {329--352},
title = {{Testing For Causality}},
volume = {2},
year = {1980}
}

@inproceedings{Bhatia08,
 author = {Bhatia, Rajesh K. and Dave, Mayank and Joshi, Ramesh C.},
 title = {Ant Colony Based Rule Generation for Reusable Software Component Retrieval},
 booktitle = {Proceedings of the 1st India Software Engineering Conference},
 series = {ISEC '08},
 year = {2008},
 isbn = {978-1-59593-917-3},
 location = {Hyderabad, India},
 pages = {129--130},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/1342211.1342237},
 doi = {10.1145/1342211.1342237},
 acmid = {1342237},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {ant colony algorithms, software component, software reuse},
} 



@book{Breiman1984,
abstract = {The methodology used to construct tree structured rules is the focus of this monograph. Unlike many other statistical procedures, which moved from pencil and paper to calculators, this text's use of trees was unthinkable before computers. Both the practical and theoretical sides have been developed in the authors' study of tree methods. Classification and Regression Trees reflects these two sides, covering the use of trees as a data analysis method, and in a more mathematical framework, proving some of their fundamental properties.},
author = {Breiman, L and Friedman, J H and Olshen, R A and Stone, C J},
booktitle = {The Wadsworth statisticsprobability series},
isbn = {0412048418},
pages = {368},
pmid = {462029},
title = {{Classification and Regression Trees}},
volume = {19},
year = {1984}
}
@article{Breiman2001,
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the corre- lation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth Interna- tional conference, ∗∗∗, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression. Keywords:},
archivePrefix = {arXiv},
arxivId = {http://dx.doi.org/10.1023\%2FA\%3A1010933404324},
author = {Breiman, L},
doi = {10.1023/A:1010933404324},
eprint = {/dx.doi.org/10.1023\%2FA\%3A1010933404324},
isbn = {0885-6125},
issn = {0885-6125},
journal = {Machine learning},
keywords = {classification,ensemble,regression},
pages = {5--32},
pmid = {21816105},
primaryClass = {http:},
title = {{Random forests}},
url = {http://link.springer.com/article/10.1023/A:1010933404324},
year = {2001}
}


@book{efron93,
  author =	"Efron, Bradley and Tibshirani, Robert J",
  title =	"An introduction to the bootstrap",
  publisher =	"Chapman and Hall",
  address =	"London",
  series =	"Mono. Stat. Appl. Probab.",
  year =	1993,
}


@INPROCEEDINGS{arcuri11,
author={Arcuri, A. and Briand, L.}, 
booktitle={ICSE'11},
title={A practical guide for using statistical tests to assess randomized algorithms in software engineering}, 
year={2011}, 
pages={1-10}}

@article{Dejaeger13,
author = {Karel Dejaeger and Thomas Verbraken and Bart Baesens},
title = {Toward Comprehensible Software Fault Prediction Models Using Bayesian Network Classifiers},
journal ={IEEE Transactions on Software Engineering},
volume = {39},
number = {2},
issn = {0098-5589},
year = {2013},
pages = {237-257},
doi = {http://doi.ieeecomputersociety.org/10.1109/TSE.2012.20},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
}

  
@ARTICLE{lessmann, 
  author={Lessmann, S. and Baesens, B. and Mues, C. and Pietsch, S.}, 
  journal={Software Engineering, IEEE Transactions on}, 
  title={Benchmarking Classification Models for Software Defect Prediction: A Proposed Framework and Novel Findings}, 
  year={2008}, 
  month={July}, 
  volume={34}, 
  number={4}, 
  pages={485-496}, 
  keywords={benchmark testing;software quality;statistical testing;benchmarking classification models;code attributes;fault-prone modules;metric-based classification;predictive classification models;proprietary data sets;software defect prediction;software quality;statistical testing procedures;testing efficiency;Complexity measures;Data mining;Formal methods;Statistical methods}, 
  doi={10.1109/TSE.2008.35}, 
  ISSN={0098-5589},}
  
@INPROCEEDINGS{smote2, 
  author={Pelayo, L. and Dick, S.}, 
  booktitle={Fuzzy Information Processing Society, 2007. NAFIPS '07. Annual Meeting of the North American}, 
  title={Applying Novel Resampling Strategies To Software Defect Prediction}, 
  year={2007}, 
  month={June}, 
  pages={69-72}, 
  keywords={learning (artificial intelligence);sampling methods;software metrics;software performance evaluation;software reliability;SMOTE technique;benchmark datasets;defect-prone modules;geometric mean classification accuracy;learning algorithms;machine learning;over-sampling minority-class examples;resampling strategy;software complexity;software defect prediction;software reliability;software sophistication;unbalanced datasets;Computer errors;Costs;Joining processes;Machine learning;Machine learning algorithms;Nearest neighbor searches;Sampling methods;Software algorithms;Software reliability;Testing}, 
  doi={10.1109/NAFIPS.2007.383813},}
@article{smote,
  title={SMOTE: synthetic minority over-sampling technique},
  author={Chawla, Nitesh V and Bowyer, Kevin W and Hall, Lawrence O and Kegelmeyer, W Philip},
  journal={Journal of artificial intelligence research},
  volume={16},
  number={1},
  pages={321--357},
  year={2002}
}

@article{fu:ase15,
  title= {Tuning for Software Analytics: is it Really Necessary?},
  booktitle={Submitted to ASE journal},
  author={Fu, Wei and Menzies, Tim and Shen, Xipeng},
  journal={Submitted to Information and Software Technology},
  year={ 2016},
  }


@INPROCEEDINGS{pelayo07, 
author={Pelayo, L. and Dick, S.}, 
booktitle={Fuzzy Information Processing Society, 2007. NAFIPS '07. Annual Meeting of the North American}, 
title={Applying Novel Resampling Strategies To Software Defect Prediction}, 
year={2007}, 
month={June}, 
pages={69-72}, 
keywords={learning (artificial intelligence);sampling methods;software metrics;software performance evaluation;software reliability;SMOTE technique;benchmark datasets;defect-prone modules;geometric mean classification accuracy;learning algorithms;machine learning;over-sampling minority-class examples;resampling strategy;software complexity;software defect prediction;software reliability;software sophistication;unbalanced datasets;Computer errors;Costs;Joining processes;Machine learning;Machine learning algorithms;Nearest neighbor searches;Sampling methods;Software algorithms;Software reliability;Testing}, 
doi={10.1109/NAFIPS.2007.383813},}

@article{sk,
  title={Ranking and clustering software cost estimation models through a multiple comparisons algorithm},
  author={Mittas, Nikolaos and Angelis, Lefteris},
  journal={Software Engineering, IEEE Transactions on},
  volume={39},
  number={4},
  pages={537--551},
  year={2013},
  publisher={IEEE}
}
@article{shepperd12a,
  author =	 {Martin J. Shepperd and Steven G. MacDonell},
  title =	 {Evaluating prediction systems in software project
                  estimation},
  journal =	 {Information {\&} Software Technology},
  volume =	 54,
  number =	 8,
  year =	 2012,
  pages =	 {820-827},
}
@article{kampenes07,
  author =	 {Vigdis By Kampenes and Tore Dyb{\aa} and Jo Erskine
                  Hannay and Dag I. K. Sj{\o}berg},
  title =	 {A systematic review of effect size in software
                  engineering experiments},
  journal =	 {Information {\&} Software Technology},
  volume =	 49,
  number =	 {11-12},
  year =	 2007,
  pages =	 {1073-1086},
}
@inproceedings{menzies2005xomo,
  title={Xomo: Understanding development options for autonomy},
  author={Menzies, Tim}
}

@article{Hansen2006,
abstract = {Derived from the concept of self-adaptation in evolution strategies, the CMA (Covariance Matrix Adaptation) adapts the covariance matrix of a multi-variate normal search distribution. The CMA was originally designed to perform well with small populations. In this review, the argument starts out with large population sizes, reflecting recent extensions of the CMA algorithm. Commonalities and differences to continuous Estimation of Distribution Algorithms are analyzed. The aspects of reliability of the estimation, overall step size control, and independence from the coordinate system (invariance) become particularly important in small populations sizes. Consequently, performing the adaptation task with small populations is more intricate.},
author = {Hansen, Nikolaus},
doi = {10.1007/11007937\_4},
isbn = {3540290060},
issn = {14349922},
journal = {Studies in Fuzziness and Soft Computing},
pages = {75--102},
title = {{The CMA evolution strategy: A comparing review}},
volume = {192},
year = {2006}
}

@article{harman12dec,
author = {Harman, Mark and Mansouri, S Afshin and Zhang, Yuanyuan},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
month = dec,
number = {1},
pages = {11:1----11:61},
title = {{Search-based Software Engineering: Trends, Techniques and Applications}},
volume = {45},
year = {2012}
}
@inproceedings{sayyad13b,
  title={Scalable product line configuration: A straw to break the camel's back},
  author={Sayyad, Abdel Salam and Ingram, Joe and Menzies, Tim and Ammar, Hany},
  booktitle={Automated Software Engineering (ASE), 2013 IEEE/ACM 28th International Conference on},
  pages={465--474},
  year={2013},
  organization={IEEE}
}

@inproceedings{sayyad13a,
  title={On the Value of User Preferences in Search-Based Software Engineering: A Case Study in Software Product Lines},
  author={Sayyad, Abdel Salam and Menzies, Tim and Ammar, Hany},
  booktitle={International Conference on Software Engineering (ICSE'13)},
  year={2013}
}

@inproceedings{Kocaguneli2013:ep,
abstract = {We offer a case study illustrating three rules for reporting$\backslash$nresearch to industrial practitioners. Firstly, report “relevant”$\backslash$nresults; e.g. this paper explores the effects of distributed development$\backslash$non software products. Second: “recheck” old results if new results call$\backslash$nthem into question. Many papers say distributed development can be$\backslash$nharmful to software quality. Previous work by Bird et al. allayed that$\backslash$nconcern but a recent paper by Posnett et al. suggests that the Bird$\backslash$nresult was biased by the kinds of files it explored. Hence, this paper$\backslash$nrechecks that result and finds significant differences in Microsoft$\backslash$nproducts (Office 2010) between software built by distributed or$\backslash$ncollocated teams. At first glance, this recheck calls into question the$\backslash$nwidespread practice of distributed development. Our third rule is to$\backslash$n“reflect” on results to avoid confusing practitioners with an arcane$\backslash$nmathematical analysis. For example, on reflection, we found that the$\backslash$neffect size of the differences seen in the collocated and distributed$\backslash$nsoftware was so small that it need not concern industrial practitioners.$\backslash$nOur conclusion is that at least for Microsoft products, distributed$\backslash$ndevelopment is not considered harmful.},
author = {Kocaguneli, Ekrem and Zimmermann, Thomas and Bird, Christian and Nagappan, Nachiappan and Menzies, Tim},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2013.6606637},
isbn = {9781467330763},
issn = {02705257},
pages = {882--890},
title = {{Distributed development considered harmful?}},
year = {2013}
}


@inproceedings{romano06,
  title="J. Romano, J. D. Kromrey, J. Coraggio, J. Skowronek",
   title="Appropriate statistics for ordinal level data: Should we really be using t-test and cohen's d for evaluating group differences on the NSSE and other surveys?",
    booktitle="Annual meeting of the Florida Association of Institutional Research",
    year=2006
    }
    

@article{boehm2009software,
  title={Software Cost Estimation with COCOMO II},
  author={Boehm, Barry W and Abts, Chris and Brown, A Winsor and Chulani, Sunita and Clark, Bradford K and Horowitz, Ellis and Madachy, Ray and Reifer, Donald J and Steece, Bert},
  year={2009},
  publisher={Prentice Hall Press}
}

@article{krall14,
author = {Krall, J and Menzies, T},
file = {:Users/timm/svns/doc/optimalML/galeTse.pdf:pdf},
journal = {IEEE Transactions on Software Engineering (to appear)},
title = {{GALE: Geometric Active Learning for Search-based Software Engineering}},
year = {2015}
}



@article{Ludewig2003,
abstract = {Modelling is a concept fundamental for soft- ware engineering. In this paper, the word is defined and discussed fromvarious perspectives. The most important types ofmodels are presented, and examples are given. Models are very useful, but sometimes also dangerous, in particular to those who use them unconsciously. Such problems are shown. Finally, the role of models in soft- ware engineering research is discussed},
author = {Ludewig, Jochen},
doi = {10.1007/s10270-003-0020-3},
file = {:Users/rkrsn/Documents/Mendeley Desktop/Ludewig\_Models in software engineering - an introduction.pdf:pdf},
isbn = {1619-1366},
issn = {1619-1366},
journal = {Software and Systems Modeling},
keywords = {Models –Software engineering –Metaphors –SESAM},
number = {1},
pages = {5--14},
title = {{Models in software engineering - an introduction}},
url = {http://link.springer.com/10.1007/s10270-003-0020-3},
volume = {2},
year = {2003}
}

@article{keung2008analogy,
  title={Analogy-X: providing statistical inference to analogy-based software cost estimation},
  author={Keung, Jacky Wai and Kitchenham, Barbara A and Jeffery, D Ross},
  journal={Software Engineering, IEEE Transactions on},
  volume={34},
  number={4},
  pages={471--484},
  year={2008},
  publisher={IEEE}
}
@article{shepperd1997estimating,
  title={Estimating software project effort using analogies},
  author={Shepperd, Martin and Schofield, Chris},
  journal={Software Engineering, IEEE Transactions on},
  volume={23},
  number={11},
  pages={736--743},
  year={1997},
  publisher={IEEE}
}

@misc{promiserepo,
  author =	 {Menzies, T. and Rees-Jones, M. and Krishna, R. and Pape, C.},
  year =	 {2015},
  title =	 {The Promise Repository of Empirical Software Engineering Data},
  notes =	 {http://openscience.us/repo. North Carolina State University, Department of Computer Science}
}

@article{Harman2009,
abstract = {In the past five years there has been a dramatic increase in work on Search Based Software Engineering (SBSE), an approach to software engineering in which search based optimisation algorithms are used to address problems in Software Engineering. SBSE has been applied to problems throughout the Software Engineering lifecycle, from requirements and project planning to maintenance and re-engineering. The approach is attractive because it offers a suite of adaptive automated and semi-automated solutions in situations typified by large complex problem spaces with multiple competing and conflicting objectives. This paper provides a review and classification of literature on SBSE. The paper identifies research trends and relationships between the techniques applied and the applications to which they have been applied and highlights gaps in the literature and avenues for further research.},
author = {Harman, M and Mansouri, Sa and Zhang, Y},
doi = {10.1016/S0950-5849(01)00189-6},
file = {::},
issn = {09505849},
journal = {Engineering},
number = {TR-09-03},
pages = {1--78},
title = {{Search Based Software Engineering: A Comprehensive Analysis and Review of Trends Techniques and Applications}},
url = {http://discovery.ucl.ac.uk/170689/},
year = {2009}
}


@article{Harman2011,
abstract = {The aim of Search Based Software Engineering (SBSE) research is to move software engineering problems from human-based search to machine-based search, using a variety of techniques from the metaheuristic search, operations research and evolutionary computation paradigms. The idea is to exploit humans creativity and machines tenacity and reliability, rather than requiring humans to perform the more tedious, error prone and thereby costly aspects of the engineering process. SBSE can also provide insights and decision support. This tutorial will present the reader with a step-by-step guide to the application of SBSE techniques to Software Engineering. It assumes neither previous knowledge nor experience with Search Based Optimisation. The intention is that the tutorial will cover sufficient material to allow the reader to become productive in successfully applying search based optimisation to a chosen Software Engineering problem of interest.},
author = {Harman, M and McMinn, P and {De Souza}, JT and Yoo, S},
doi = {10.1007/978-3-642-25231-0\_1},
journal = {Search},
pages = {1--59},
title = {{Search based software engineering: Techniques, taxonomy, tutorial}},
url = {http://discovery.ucl.ac.uk/1340709/},
volume = {2012},
year = {2011}
}


@article{walkerden1999empirical,
  title={An empirical study of analogy-based software effort estimation},
  author={Walkerden, Fiona and Jeffery, Ross},
  journal={Empirical software engineering},
  volume={4},
  number={2},
  pages={135--158},
  year={1999},
  publisher={Springer}
}
@ARTICLE{6600685, 
author={Menzies, T. and Brady, A. and Keung, J. and Hihn, J. and Williams, S. and El-Rawas, O. and Green, P. and Boehm, B.}, 
journal={Software Engineering, IEEE Transactions on}, 
title={Learning Project Management Decisions: A Case Study with Case-Based Reasoning versus Data Farming}, 
year={2013}, 
month={Dec}, 
volume={39}, 
number={12}, 
pages={1698-1713}, 
keywords={Monte Carlo methods;case-based reasoning;data handling;learning (artificial intelligence);project management;sampling methods;software management;CBR;Monte Carlo sampling;SEESAW;case-based reasoning;data farming;project management decision learning;software project data;Data models;Mathematical model;Monte Carlo methods;Project management;Search methods;Software engineering;COCOMO;Search-based software engineering;case-based reasoning;data farming}, 
doi={10.1109/TSE.2013.43}, 
ISSN={0098-5589},}
@inproceedings{kocaguneli2010use,
  title={When to use data from other projects for effort estimation},
  author={Kocaguneli, Ekrem and Gay, Gregory and Menzies, Tim and Yang, Ye and Keung, Jacky W},
  booktitle={Proceedings of the IEEE/ACM international conference on Automated software engineering},
  pages={321--324},
  year={2010},
  organization={ACM}
}
@article{kocaguneli2012exploiting,
  title={Exploiting the essential assumptions of analogy-based effort estimation},
  author={Kocaguneli, Ekrem and Menzies, Tim and Bener, Ayse and Keung, Jacky W},
  journal={Software Engineering, IEEE Transactions on},
  volume={38},
  number={2},
  pages={425--438},
  year={2012},
  publisher={IEEE}
}
@ARTICLE{1438374, 
author={Myrtveit, I. and Stensrud, E. and Shepperd, M.}, 
journal={Software Engineering, IEEE Transactions on}, 
title={Reliability and validity in comparative studies of software prediction models}, 
year={2005}, 
month={May}, 
volume={31}, 
number={5}, 
pages={380-391}, 
keywords={convergence;function approximation;learning (artificial intelligence);program verification;regression analysis;software cost estimation;software metrics;software reliability;accuracy indicator;analogy estimation;arbitrary function approximators;convergence;cost estimation;cross validation;data sample;empirical method;machine learning model;regression model;simulation;software metrics;software prediction model;software reliability;software validity;Analytical models;Artificial neural networks;Convergence;Cost function;Machine learning;Mathematical model;Maximum likelihood estimation;Predictive models;Programming;Regression analysis;Index Terms- Software metrics;accuracy indicators.;arbitrary function approximators;cost estimation;cross-validation;empirical methods;estimation by analogy;machine learning;regression analysis;reliability;simulation;validity}, 
doi={10.1109/TSE.2005.58}, 
ISSN={0098-5589},}
@article{hall03,
  title={Benchmarking attribute selection techniques for discrete class data mining},
  author={Hall, Mark Andrew and Holmes, Geoffrey},
  journal={Knowledge and Data Engineering, IEEE Transactions on},
  volume={15},
  number={6},
  pages={1437--1447},
  year={2003},
  publisher={IEEE}
}


@inproceedings{Mkaouer14,
 author = {Mkaouer, Mohamed Wiem and Kessentini, Marouane and Bechikh, Slim and Deb, Kalyanmoy and \'{O} Cinn{\'e}ide, Mel},
 title = {Recommendation System for Software Refactoring Using Innovization and Interactive Dynamic Optimization},
 booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
 series = {ASE '14},
 year = {2014},
 isbn = {978-1-4503-3013-8},
 location = {Vasteras, Sweden},
 pages = {331--336},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2642937.2642965},
 doi = {10.1145/2642937.2642965},
 acmid = {2642965},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {refactoring, search based software engineering, software quality},
} 


@inproceedings{posnett11,
  author =	"Daryl Posnett and Vladimir Filkov and Premkumar Devanbu",
  title =	"Ecological Inference in Empirical Software
                  Engineering",
  booktitle =	"Proceedings of ASE'11",
  year =	2011
}

@Inbook{Moghadam2011,
author="Moghadam, Iman Hemati",
chapter="Multi-level Automated Refactoring Using Design Exploration",
title="Search Based Software Engineering: Third International Symposium, SSBSE 2011, Szeged, Hungary, September 10-12, 2011. Proceedings",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="70--75",
isbn="978-3-642-23716-4",
doi="10.1007/978-3-642-23716-4_9",
url="http://dx.doi.org/10.1007/978-3-642-23716-4_9"
}



@article{betten14,
year={2014},
issn={1382-3256},
journal={Empirical Software Engineering},
doi={10.1007/s10664-013-9292-6},
title={Towards improving statistical modeling of software engineering data: think locally, act globally!},
url={http://dx.doi.org/10.1007/s10664-013-9292-6},
publisher={Springer US},
keywords={Software metrics; Statistical modeling; Clustering},
author={Bettenburg, Nicolas and Nagappan, Meiyappan and Hassan, Ahmed E.},
pages={1-42},
language={English}
}



@inproceedings{yang11,
  author =	{Ye Yang and Lang Xie and Zhimin He and Qi Li and Vu
                  Nguyen and Barry W. Boehm and Ricardo Valerdi},
  title =	{Local bias and its impacts on the performance of
                  parametric estimation models},
  booktitle =	{PROMISE},
  year =	2011,
}



@article{yang13,
  author =	{Ye Yang and Zhimin He and Ke Mao and Qi Li and Vu
                  Nguyen and Barry W. Boehm and Ricardo Valerdi},
  title =	{Analyzing and handling local bias for calibrating
                  parametric cost estimation models},
  journal =	{Information {\&} Software Technology},
  volume =	55,
  number =	8,
  year =	2013,
  pages =	{1496-1511},
  ee =	{http://dx.doi.org/10.1016/j.infsof.2013.03.002},
  bibsource =	{DBLP, http://dblp.uni-trier.de}
}



@article{minku13,
  author    = {Leandro L. Minku and
               Xin Yao},
  title     = {Ensembles and locality: Insight on improving software effort
               estimation},
  journal   = {Information {\&} Software Technology},
  volume    = {55},
  number    = {8},
  year      = {2013},
  pages     = {1512-1528},
}


@inproceedings{sven12,
  title={Predicting performance via automated feature-interaction detection},
  author={Siegmund, Norbert and Kolesnikov, Sergiy S and K{\"a}stner, Christian and Apel, Sven and Batory, Don and Rosenm{\"u}ller, Marko and Saake, Gunter},
  booktitle={Proceedings of the 34th International Conference on Software Engineering},
  pages={167--177},
  year={2012},
  organization={IEEE Press}
}
@inproceedings{vapp,
  title={Variability-aware performance prediction: A statistical learning approach},
  author={Guo, Jianmei and Czarnecki, Krzysztof and Apel, Sven and Siegmund, Norbert and Wasowski, Andrzej},
  booktitle={Automated Software Engineering (ASE), 2013 IEEE/ACM 28th International Conference on},
  pages={301--311},
  year={2013},
  organization={IEEE}
}
@article{Menzies2010,
abstract = {Building quality software is expensive and software quality assurance (QA) budgets are limited. Data miners can learn defect predictors from static code features which can be used to control QA resources; e.g. to focus on the parts of the code predicted to be more defective. Recent results show that better data mining technology is not leading to better defect predictors. We hypothesize that we have reached the limits of the standard learning goal of maximizing area under the curve (AUC) of the probability of false alarms and probability of detection AUC(pd, pf) ; i.e. the area under the curve of a probability of false alarm versus probability of detection. Accordingly, we explore changing the standard goal. Learners that maximize AUC(effort, pd) find the smallest set of modules that contain the most errors. WHICH is a meta-learner framework that can be quickly customized to different goals. When customized to AUC(effort, pd), WHICH out-performs all the data mining methods studied here. More importantly, measured in terms of this new goal, certain widely used learners perform much worse than simple manual methods. Hence, we advise against the indiscriminate use of learners. Learners must be chosen and customized to the goal at hand. With the right architecture (e.g. WHICH), tuning a learner to specific local business goals can be a simple task.},
author = {Menzies, Tim and Milton, Zach and Turhan, Burak and Cukic, Bojan and Jiang, Yue and Bener, Ayşe},
doi = {10.1007/s10515-010-0069-5},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {Defect prediction,Static code features,Which},
number = {4},
pages = {375--407},
title = {{Defect prediction from static code features: Current results, limitations, new approaches}},
volume = {17},
year = {2010}
}



@article{Irani1993,
abstract = {Since most real-world applications of classification learning involve continuous-valued attributes, properly addressing the discretization process is an important problem. This paper addresses the use of the entropy minimization heuristic for discrctizing the range of a continuous-valued attribute into multiple intervals. We briefly present theoretical evidence for the apropiateness of this heuristic for use in the binary discretization algorithm used in ID3, C4, CART, and other learning algorithms. The results serve to justify extending the algorithm to derive multiple intervals. We formally derive a criterion based on the minimum description length principle for deciding the partition of intervals. We demonstrate via empirical evaluation on several real-world data sets that better decision trees are obtained using the new multi-interval algorithm.},
author = {Irani, KB and Fayyad, UM},
file = {::},
isbn = {1-55860-300-X},
issn = {15730565},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
pages = {1022--1027},
title = {{Multi-lnterval Discretization of Continuous-Valued Attributes for Classification learning}},
year = {1993}
}


@article{Anda2009,
abstract = {The scientific study of a phenomenon requires it to be reproducible. Mature engineering industries are recognized by projects and products that are, to some extent, reproducible. Yet, reproducibility in software engineering (SE) has not been investigated thoroughly, despite the fact that lack of reproducibility has both practical and scientific consequences. We report a longitudinal multiple-case study of variations and reproducibility in software development, from bidding to deployment, on the basis of the same requirement specification. In a call for tender to 81 companies, 35 responded. Four of them developed the system independently. The firm price, planned schedule, and planned development process, had, respectively, ldquolow,rdquo ldquolow,rdquo and ldquomediumrdquo reproducibilities. The contractor's costs, actual lead time, and schedule overrun of the projects had, respectively, ldquomedium,rdquo ldquohigh,rdquo and ldquolowrdquo reproducibilities. The quality dimensions of the delivered products, reliability, usability, and maintainability had, respectively, ldquolow,rdquo "high,rdquo and ldquolowrdquo reproducibilities. Moreover, variability for predictable reasons is also included in the notion of reproducibility. We found that the observed outcome of the four development projects matched our expectations, which were formulated partially on the basis of SE folklore. Nevertheless, achieving more reproducibility in SE remains a great challenge for SE research, education, and industry.},
author = {Anda, Bente C D and Sj\o berg, Dag I K and Mockus, Audris},
doi = {10.1109/TSE.2008.89},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Multiple-case study,Software engineering life cycle,Software process,Software project success,Software quality},
number = {3},
pages = {407--429},
title = {{Variability and reproducibility in software engineering: A study of four companies that developed the same system}},
volume = {35},
year = {2009}
}


@misc{promise,
  authors =	 "Menzies, T., Rees-Jones, M.,
                  Krishna, R., Pape, C.",
  year =	 2015,
  title =	 "The {P}romise {R}epository of
                  {E}mpirical {S}oftware {E}ngineering
                  {D}ata",
  note =	 "http://openscience.us/repo.  North
                  Carolina State University,
                  Department of Computer Science"
}

@mastersthesis{div14,
  title="Exploring Essential content of Defect Prediction 
         and Effort Estimation through Data Reduction",
  year=2014,
  author="Divya Ganesan",
  school="Computer Science, West Virginia University"
 }
 
 

@inproceedings{me12c,
annote = {Available from http://menzies.us/pdf/12idea.pdf},
author = {Borges, R and Menzies, T},
booktitle = {Proceedings of PROMISE'12, Lund, Sweden},
title = {{Learning to Change Projects}},
year = {2012}
}
 
@mastersthesis{nva14,
  title="Cross Trees: Visualizing Estimations using Decision Trees",
  year=2014,
  author="Naveen  Lekkalapudi",
  school="Computer Science, West Virginia University"
 }

@book{fastmap,
  title={FastMap: A fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets},
  author={Faloutsos, Christos and Lin, King-Ip},
  volume={24},
  number={2},
  year={1995},
  publisher={ACM}
}
@ARTICLE{6600685, 
author={Menzies, T. and Brady, A. and Keung, J. and Hihn, J. and Williams, S. and El-Rawas, O. and Green, P. and Boehm, B.}, 
journal={Software Engineering, IEEE Transactions on}, 
title={Learning Project Management Decisions: A Case Study with Case-Based Reasoning versus Data Farming}, 
year={2013}, 
month={Dec}, 
volume={39}, 
number={12}, 
pages={1698-1713}, 
keywords={Monte Carlo methods;case-based reasoning;data handling;learning (artificial intelligence);project management;sampling methods;software management;CBR;Monte Carlo sampling;SEESAW;case-based reasoning;data farming;project management decision learning;software project data;Data models;Mathematical model;Monte Carlo methods;Project management;Search methods;Software engineering;COCOMO;Search-based software engineering;case-based reasoning;data farming}, 
doi={10.1109/TSE.2013.43}, 
ISSN={0098-5589},}
@inproceedings{kocaguneli2010use,
  title={When to use data from other projects for effort estimation},
  author={Kocaguneli, Ekrem and Gay, Gregory and Menzies, Tim and Yang, Ye and Keung, Jacky W},
  booktitle={Proceedings of the IEEE/ACM international conference on Automated software engineering},
  pages={321--324},
  year={2010},
  organization={ACM}
}

@inproceedings{jureczko10,
author = {Jureczko, Marian and Madeyski, Lech},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
pages = {9:1----9:10},
publisher = {ACM},
series = {PROMISE '10},
title = {{Towards identifying software project clusters with regard to defect prediction}},
year = {2010}
}
@article{mittas13,
  author =	{Nikolaos Mittas and Lefteris Angelis},
  title =	{Ranking and Clustering Software Cost Estimation
                  Models through a Multiple Comparisons Algorithm},
  journal =	{IEEE Trans. Software Eng.},
  volume =	39,
  number =	4,
  year =	2013,
  pages =	{537-551},
}

@article{howase,
author = {Krishna, Rahul and Menzies, Tim and Shen, Xipeng and Marcus, Andrian},
title = {{Learning Actionable Analytics (with applications for reducing defects and reducing runtimes)}},
journal = {Submitted to ASE '15, Lincoln, Nebraska},
year = {2015}
}
@inproceedings {prem16,
  title={Belief \& evidence in empirical software engineering},
  author={Devanbu, Prem and Zimmermann, Thomas and Bird, Christian},
  booktitle={Proceedings of the 38th International Conference on Software Engineering},
  pages={108--119},
  year={2016},
  organization={ACM}
}